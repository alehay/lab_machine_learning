{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b6e234",
   "metadata": {},
   "source": [
    "# Video Games JP_Sales: исправленная версия (Name + franchise features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3728be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 11703 Test rows: 5016 All rows: 16719\n",
      "Columns: ['Name', 'Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_PATH = \"Video_Games.csv\"\n",
    "TEST_PATH  = \"Video_Games_Test.csv\"\n",
    "TARGET = \"JP_Sales\"\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# на случай \"Id \" / \" id\" / пробелов\n",
    "train_df.columns = train_df.columns.str.strip()\n",
    "test_df.columns  = test_df.columns.str.strip()\n",
    "\n",
    "assert TARGET in train_df.columns, f\"'{TARGET}' not found in train\"\n",
    "\n",
    "y = train_df[TARGET].astype(float)\n",
    "X_train_raw = train_df.drop(columns=[TARGET]).copy()\n",
    "X_test_raw  = test_df.copy()\n",
    "\n",
    "def find_id_col(df):\n",
    "    for c in df.columns:\n",
    "        if str(c).strip().lower() == \"id\":\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "id_col_train = find_id_col(X_train_raw)\n",
    "id_col_test  = find_id_col(X_test_raw)\n",
    "\n",
    "if id_col_test is not None:\n",
    "    test_ids = X_test_raw[id_col_test].values\n",
    "else:\n",
    "    test_ids = np.arange(1, len(X_test_raw) + 1)\n",
    "\n",
    "if id_col_train is not None:\n",
    "    X_train_raw.drop(columns=[id_col_train], inplace=True)\n",
    "if id_col_test is not None:\n",
    "    X_test_raw.drop(columns=[id_col_test], inplace=True)\n",
    "\n",
    "X_all = pd.concat([X_train_raw, X_test_raw], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Train rows:\", len(X_train_raw), \"Test rows:\", len(X_test_raw), \"All rows:\", len(X_all))\n",
    "print(\"Columns:\", list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b747d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Name Platform  Year_of_Release  \\\n",
      "0                      Rapala Trophies      PSP           2006.0   \n",
      "1              New Super Mario Bros. U     WiiU           2012.0   \n",
      "2                               Robots      PS2           2005.0   \n",
      "3                       Hamster Club 3      GBA           2002.0   \n",
      "4                         Formula 1 06      PS2           2006.0   \n",
      "5                     My Ballet Studio      Wii           2009.0   \n",
      "6                           EVE Online       PC           2003.0   \n",
      "7  S.T.A.L.K.E.R.: Shadow of Chernobyl       PC           2007.0   \n",
      "8                      Madden NFL 2003       XB           2002.0   \n",
      "9              Shin Super Robot Taisen       PS           1996.0   \n",
      "\n",
      "          Genre                    Publisher  NA_Sales  EU_Sales  Other_Sales  \\\n",
      "0        Sports                   Activision      0.04      0.00         0.00   \n",
      "1      Platform                     Nintendo      2.30      1.34         0.32   \n",
      "2        Action                Vivendi Games      0.18      0.14         0.05   \n",
      "3    Simulation                      Jorudan      0.00      0.00         0.01   \n",
      "4        Racing  Sony Computer Entertainment      0.00      0.00         0.00   \n",
      "5    Simulation                    505 Games      0.02      0.00         0.00   \n",
      "6  Role-Playing                          CCP      0.00      0.19         0.01   \n",
      "7       Shooter                          THQ      0.01      0.04         0.01   \n",
      "8        Sports              Electronic Arts      0.67      0.02         0.03   \n",
      "9  Role-Playing                    Banpresto      0.00      0.00         0.04   \n",
      "\n",
      "   Critic_Score  Critic_Count  User_Score  User_Count  \\\n",
      "0           NaN           NaN         NaN         NaN   \n",
      "1          84.0          70.0         8.1       733.0   \n",
      "2          53.0           6.0         6.0         8.0   \n",
      "3           NaN           NaN         NaN         NaN   \n",
      "4           NaN           NaN         NaN         NaN   \n",
      "5           NaN           NaN         NaN         NaN   \n",
      "6          69.0          22.0         7.5       280.0   \n",
      "7          82.0          44.0         8.4      1088.0   \n",
      "8          92.0          16.0         8.3        16.0   \n",
      "9           NaN           NaN         NaN         NaN   \n",
      "\n",
      "                        Developer Rating  \n",
      "0              Sand Grain Studios      E  \n",
      "1                        Nintendo      E  \n",
      "2  Eurocom Entertainment Software      E  \n",
      "3                             NaN    NaN  \n",
      "4                             NaN    NaN  \n",
      "5                       505 Games      E  \n",
      "6                             CCP      T  \n",
      "7                  GSC Game World      M  \n",
      "8                      EA Tiburon      E  \n",
      "9                             NaN    NaN  \n",
      "                            Name Platform  Year_of_Release         Genre  \\\n",
      "0   BeatMania IIDX 13: DistorteD      PS2           2007.0    Simulation   \n",
      "1         Rugrats: Castle Capers      GBA           2001.0        Action   \n",
      "2                    Overlord II      PS3           2009.0        Action   \n",
      "3  Barbie as The Island Princess      GBA           2007.0     Adventure   \n",
      "4          Petz: Hamsterz Life 2      GBA           2007.0          Misc   \n",
      "5              Rollcage Stage II       PS           2000.0        Racing   \n",
      "6                      Syndicate      PS3           2012.0       Shooter   \n",
      "7                    Sakura Wars       DC           2000.0     Adventure   \n",
      "8  Pokemon Ruby/Pokemon Sapphire      GBA           2002.0  Role-Playing   \n",
      "9   Pictionary: Ultimate Edition      PS3           2011.0          Misc   \n",
      "\n",
      "                      Publisher  NA_Sales  EU_Sales  Other_Sales  \\\n",
      "0  Konami Digital Entertainment      0.00      0.00         0.00   \n",
      "1                           THQ      0.33      0.12         0.01   \n",
      "2                   Codemasters      0.11      0.15         0.06   \n",
      "3                    Activision      0.16      0.06         0.00   \n",
      "4                       Ubisoft      0.01      0.00         0.00   \n",
      "5   Sony Computer Entertainment      0.05      0.03         0.01   \n",
      "6                      EA Games      0.07      0.06         0.02   \n",
      "7                          Sega      0.00      0.00         0.00   \n",
      "8                      Nintendo      6.06      3.90         0.50   \n",
      "9                           THQ      0.15      0.06         0.03   \n",
      "\n",
      "   Critic_Score  Critic_Count  User_Score  User_Count            Developer  \\\n",
      "0           NaN           NaN         NaN         NaN                  NaN   \n",
      "1           NaN           NaN         NaN         NaN                  NaN   \n",
      "2          72.0          42.0         7.6        24.0      Triumph Studios   \n",
      "3           NaN           NaN         NaN         NaN                  NaN   \n",
      "4           NaN           NaN         NaN         NaN                  NaN   \n",
      "5          85.0           7.0         8.9        16.0  Attention To Detail   \n",
      "6          75.0          29.0         6.5       106.0           Starbreeze   \n",
      "7           NaN           NaN         NaN         NaN                  NaN   \n",
      "8           NaN           NaN         NaN         NaN                  NaN   \n",
      "9          62.0           4.0         NaN         NaN      Page 44 Studios   \n",
      "\n",
      "  Rating  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2      T  \n",
      "3    NaN  \n",
      "4    NaN  \n",
      "5      E  \n",
      "6      M  \n",
      "7    NaN  \n",
      "8    NaN  \n",
      "9      E  \n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw.head(10))\n",
    "print(X_test_raw.head(10))\n",
    "print('*' * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc4059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all\n",
      "                                  Name Platform  Year_of_Release  \\\n",
      "0                      Rapala Trophies      PSP           2006.0   \n",
      "1              New Super Mario Bros. U     WiiU           2012.0   \n",
      "2                               Robots      PS2           2005.0   \n",
      "3                       Hamster Club 3      GBA           2002.0   \n",
      "4                         Formula 1 06      PS2           2006.0   \n",
      "5                     My Ballet Studio      Wii           2009.0   \n",
      "6                           EVE Online       PC           2003.0   \n",
      "7  S.T.A.L.K.E.R.: Shadow of Chernobyl       PC           2007.0   \n",
      "8                      Madden NFL 2003       XB           2002.0   \n",
      "9              Shin Super Robot Taisen       PS           1996.0   \n",
      "\n",
      "          Genre                    Publisher  NA_Sales  EU_Sales  Other_Sales  \\\n",
      "0        Sports                   Activision      0.04      0.00         0.00   \n",
      "1      Platform                     Nintendo      2.30      1.34         0.32   \n",
      "2        Action                Vivendi Games      0.18      0.14         0.05   \n",
      "3    Simulation                      Jorudan      0.00      0.00         0.01   \n",
      "4        Racing  Sony Computer Entertainment      0.00      0.00         0.00   \n",
      "5    Simulation                    505 Games      0.02      0.00         0.00   \n",
      "6  Role-Playing                          CCP      0.00      0.19         0.01   \n",
      "7       Shooter                          THQ      0.01      0.04         0.01   \n",
      "8        Sports              Electronic Arts      0.67      0.02         0.03   \n",
      "9  Role-Playing                    Banpresto      0.00      0.00         0.04   \n",
      "\n",
      "   Critic_Score  Critic_Count  User_Score  User_Count  \\\n",
      "0           NaN           NaN         NaN         NaN   \n",
      "1          84.0          70.0         8.1       733.0   \n",
      "2          53.0           6.0         6.0         8.0   \n",
      "3           NaN           NaN         NaN         NaN   \n",
      "4           NaN           NaN         NaN         NaN   \n",
      "5           NaN           NaN         NaN         NaN   \n",
      "6          69.0          22.0         7.5       280.0   \n",
      "7          82.0          44.0         8.4      1088.0   \n",
      "8          92.0          16.0         8.3        16.0   \n",
      "9           NaN           NaN         NaN         NaN   \n",
      "\n",
      "                        Developer Rating  \n",
      "0              Sand Grain Studios      E  \n",
      "1                        Nintendo      E  \n",
      "2  Eurocom Entertainment Software      E  \n",
      "3                             NaN    NaN  \n",
      "4                             NaN    NaN  \n",
      "5                       505 Games      E  \n",
      "6                             CCP      T  \n",
      "7                  GSC Game World      M  \n",
      "8                      EA Tiburon      E  \n",
      "9                             NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"X_all\")\n",
    "print(X_all.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3dda77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_478681/2277753913.py:52: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_roman\"] = s.str.contains(ROMAN_RE, regex=True).astype(int)\n",
      "/tmp/ipykernel_478681/2277753913.py:53: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_edition_word\"] = s.str.contains(EDITION_RE, regex=True).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "EDITION_RE = re.compile(\n",
    "    r\"\\b(remaster(ed)?|hd|definitive|ultimate|complete|collector'?s|\"\n",
    "    r\"game of the year|goty|gold|deluxe|premium|special|limited|edition|\"\n",
    "    r\"director'?s cut|anniversary|bundle|collection)\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "ROMAN_RE = re.compile(r\"\\b(i{1,3}|iv|v|vi{0,3}|ix|x|xi|xii|xiii|xiv|xv)\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "def normalize_name(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\").fillna(\"__MISSING__\").str.lower()\n",
    "    # unify separators\n",
    "    s = s.str.replace(r\"[™®©]\", \"\", regex=True)\n",
    "    s = s.str.replace(r\"[\\(\\)\\[\\]\\{\\}]\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"[/:;,\\.\\!\\?\\|\\\\]\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"[-_]+\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "def split_base(s: pd.Series) -> pd.Series:\n",
    "    # base before ':' or long dash patterns (common subtitle separators)\n",
    "    s2 = s.str.replace(r\"\\s*:\\s*\", \" : \", regex=True)\n",
    "    # split on \":\" or \" - \" (keep left)\n",
    "    base = s2.str.split(r\"\\s:\\s|\\s-\\s|\\s—\\s\", n=1, expand=True)[0]\n",
    "    base = base.str.strip()\n",
    "    return base.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "def franchise_key(s: pd.Series) -> pd.Series:\n",
    "    s = s.copy()\n",
    "    s = s.str.replace(EDITION_RE, \" \", regex=True)\n",
    "    s = s.str.replace(ROMAN_RE, \" \", regex=True)\n",
    "    s = s.str.replace(r\"\\b\\d+\\b\", \" \", regex=True)          # sequel numbers / years in title\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "# usage (на X_all)\n",
    "if \"Name\" in X_all.columns:\n",
    "    X_all[\"Name_norm\"] = normalize_name(X_all[\"Name\"])\n",
    "    X_all[\"Name_base\"] = split_base(X_all[\"Name_norm\"])\n",
    "    X_all[\"Franchise_key\"] = franchise_key(X_all[\"Name_base\"])\n",
    "\n",
    "\n",
    "def add_name_flags(df):\n",
    "    s = df[\"Name_norm\"].astype(\"string\")\n",
    "    df[\"name_len\"] = s.str.len().fillna(0).astype(int)\n",
    "    df[\"name_words\"] = s.str.split().str.len().fillna(0).astype(int)\n",
    "    df[\"has_colon_or_dash\"] = s.str.contains(r\"\\s:\\s|\\s-\\s|\\s—\\s\", regex=True).astype(int)\n",
    "    df[\"has_digit\"] = s.str.contains(r\"\\d\").astype(int)\n",
    "    df[\"has_roman\"] = s.str.contains(ROMAN_RE, regex=True).astype(int)\n",
    "    df[\"has_edition_word\"] = s.str.contains(EDITION_RE, regex=True).astype(int)\n",
    "    return df\n",
    "\n",
    "if \"Name_norm\" in X_all.columns:\n",
    "    X_all = add_name_flags(X_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d026958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def add_oof_mean_count_features(\n",
    "    X: pd.DataFrame,\n",
    "    y,\n",
    "    X_test: pd.DataFrame,\n",
    "    keys,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "    alpha=5.0,          # smoothing strength; 0 = без сглаживания\n",
    "    fill_value=\"__MISSING__\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Добавляет OOF признаки:\n",
    "      - <key>__jp_mean  : OOF mean (optionally smoothed)\n",
    "      - <key>__jp_cnt   : OOF count\n",
    "    и для test — статистики по full train.\n",
    "    \"\"\"\n",
    "    if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "        y = np.asarray(y).reshape(-1)\n",
    "    else:\n",
    "        y = np.asarray(y).reshape(-1)\n",
    "\n",
    "    assert len(X) == len(y), \"X and y must have same length\"\n",
    "\n",
    "    X = X.reset_index(drop=True).copy()\n",
    "    X_test = X_test.reset_index(drop=True).copy()\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    global_mean = float(np.mean(y))\n",
    "\n",
    "    def _compute_for_key(key_col: str):\n",
    "        # гарантируем отсутствие NA в ключе\n",
    "        X[key_col] = X[key_col].astype(\"string\").fillna(fill_value)\n",
    "        X_test[key_col] = X_test[key_col].astype(\"string\").fillna(fill_value)\n",
    "\n",
    "        oof_mean = np.full(len(X), global_mean, dtype=float)\n",
    "        oof_cnt  = np.zeros(len(X), dtype=float)\n",
    "\n",
    "        for tr_idx, va_idx in kf.split(X):\n",
    "            tr_keys = X.loc[tr_idx, key_col].values\n",
    "\n",
    "            stats = (\n",
    "                pd.DataFrame({key_col: tr_keys, \"y\": y[tr_idx]})\n",
    "                .groupby(key_col)[\"y\"]\n",
    "                .agg([\"mean\", \"count\"])\n",
    "            )\n",
    "\n",
    "            va_keys = X.loc[va_idx, key_col]\n",
    "            m = va_keys.map(stats[\"mean\"])\n",
    "            c = va_keys.map(stats[\"count\"])\n",
    "\n",
    "            m = m.fillna(global_mean).astype(float).values\n",
    "            c = c.fillna(0).astype(float).values\n",
    "\n",
    "            if alpha and alpha > 0:\n",
    "                # smoothed mean: (m*c + global*alpha)/(c+alpha)\n",
    "                m = (m * c + global_mean * alpha) / (c + alpha)\n",
    "\n",
    "            oof_mean[va_idx] = m\n",
    "            oof_cnt[va_idx]  = c\n",
    "\n",
    "        # full-train stats for test\n",
    "        full_stats = (\n",
    "            pd.DataFrame({key_col: X[key_col].values, \"y\": y})\n",
    "            .groupby(key_col)[\"y\"]\n",
    "            .agg([\"mean\", \"count\"])\n",
    "        )\n",
    "\n",
    "        te_m = X_test[key_col].map(full_stats[\"mean\"]).fillna(global_mean).astype(float).values\n",
    "        te_c = X_test[key_col].map(full_stats[\"count\"]).fillna(0).astype(float).values\n",
    "        if alpha and alpha > 0:\n",
    "            te_m = (te_m * te_c + global_mean * alpha) / (te_c + alpha)\n",
    "\n",
    "        X[f\"{key_col}__jp_mean\"] = oof_mean\n",
    "        X[f\"{key_col}__jp_cnt\"]  = oof_cnt\n",
    "        X_test[f\"{key_col}__jp_mean\"] = te_m\n",
    "        X_test[f\"{key_col}__jp_cnt\"]  = te_c\n",
    "\n",
    "    for k in keys:\n",
    "        if k in X.columns and k in X_test.columns:\n",
    "            _compute_for_key(k)\n",
    "        else:\n",
    "            print(f\"SKIP '{k}': not present in both X and X_test\")\n",
    "\n",
    "    return X, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3f0f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_cols: ['Name']\n",
      "cat_cols: ['Platform', 'Genre', 'Publisher', 'Developer', 'Rating', 'Name_norm', 'Name_base', 'Franchise_key']\n",
      "num_cols: ['Year_of_Release', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'name_len', 'name_words', 'has_colon_or_dash', 'has_digit', 'has_roman', 'has_edition_word']\n",
      "NUM: 14 cols -> (16719, 14)\n",
      "CAT: 8 cols -> OHE shape (16719, 123)\n",
      "TEXT 'Name': TF-IDF shape (16719, 64589), vocab=64589\n",
      "TOTAL features: 64726\n",
      "X_train_proc: (11703, 64726) X_test_proc: (5016, 64726)\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS ON ALL DATA (train+test), THEN SPLIT BACK\n",
    "# =========================\n",
    "\n",
    "def make_ohe(min_freq: int):\n",
    "    \"\"\"Совместимость со sklearn: sparse_output (новый) vs sparse (старый).\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", min_frequency=min_freq, sparse_output=True)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", min_frequency=min_freq, sparse=True)\n",
    "\n",
    "def preprocess_all_data(\n",
    "    X_all_df: pd.DataFrame,\n",
    "    text_cols,\n",
    "    cat_cols,\n",
    "    num_cols,\n",
    "    min_freq: int = 50,\n",
    "    tfidf_max_features: int = 80000,\n",
    "):\n",
    "    mats = []\n",
    "\n",
    "    # 1) NUM\n",
    "    if len(num_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy=\"median\")\n",
    "        num_scaler = StandardScaler(with_mean=False)\n",
    "        num_data = num_scaler.fit_transform(num_imputer.fit_transform(X_all_df[num_cols]))\n",
    "        mats.append(sparse.csr_matrix(num_data))\n",
    "        print(f\"NUM: {len(num_cols)} cols -> {num_data.shape}\")\n",
    "\n",
    "    # 2) CAT (ИСПРАВЛЕНО!)\n",
    "    if len(cat_cols) > 0:\n",
    "        cat_df = X_all_df[cat_cols].fillna(\"__MISSING__\").astype(str)\n",
    "        ohe = make_ohe(min_freq)\n",
    "        cat_ohe = ohe.fit_transform(cat_df)\n",
    "        mats.append(cat_ohe.tocsr())\n",
    "        print(f\"CAT: {len(cat_cols)} cols -> OHE shape {cat_ohe.shape}\")\n",
    "\n",
    "    # 3) TEXT (TF-IDF)\n",
    "    def _flatten_1d(x):\n",
    "        arr = np.asarray(x).ravel().astype(str)\n",
    "        return np.where((arr == 'nan') | (arr == 'None') | (arr == '<NA>'), '', arr)\n",
    "\n",
    "    for c in text_cols:\n",
    "        # ИСПРАВЛЕНИЕ: fillna ПЕРЕД astype\n",
    "        text_data = X_all_df[c].fillna(\"\").astype(str).values\n",
    "        text_data = _flatten_1d(text_data.reshape(-1, 1))\n",
    "        \n",
    "        tfidf = TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=(3, 5),\n",
    "            min_df=2,\n",
    "            max_features=tfidf_max_features,\n",
    "        )\n",
    "        tfidf_mat = tfidf.fit_transform(text_data)\n",
    "        mats.append(tfidf_mat.tocsr())\n",
    "        print(f\"TEXT '{c}': TF-IDF shape {tfidf_mat.shape}, vocab={len(tfidf.vocabulary_)}\")\n",
    "\n",
    "    # stack\n",
    "    X_proc = sparse.hstack(mats, format=\"csr\")\n",
    "    print(f\"TOTAL features: {X_proc.shape[1]}\")\n",
    "    return X_proc\n",
    "\n",
    "# Выбираем колонки\n",
    "text_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_all.columns]\n",
    "\n",
    "cat_cols_all = X_all.select_dtypes(include=[\"object\", \"category\", \"bool\", \"string\"]).columns.tolist()\n",
    "cat_cols = [c for c in cat_cols_all if c not in set(text_cols)]\n",
    "\n",
    "num_cols = [c for c in X_all.columns if c not in set(cat_cols) and c not in set(text_cols)]\n",
    "\n",
    "print(\"text_cols:\", text_cols)\n",
    "print(\"cat_cols:\", cat_cols)\n",
    "print(\"num_cols:\", num_cols)\n",
    "\n",
    "X_all_proc = preprocess_all_data(\n",
    "    X_all,\n",
    "    text_cols=text_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    num_cols=num_cols,\n",
    "    min_freq=50,\n",
    "    tfidf_max_features=80000,\n",
    ")\n",
    "\n",
    "n_train = len(X_train_raw)\n",
    "X_train_proc = X_all_proc[:n_train]\n",
    "X_test_proc  = X_all_proc[n_train:]\n",
    "\n",
    "print(\"X_train_proc:\", X_train_proc.shape, \"X_test_proc:\", X_test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b090866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge][fold 1] MAE=0.075268 RMSE=0.188657\n",
      "[Ridge][fold 2] MAE=0.078290 RMSE=0.232864\n",
      "[Ridge][fold 3] MAE=0.074903 RMSE=0.194910\n",
      "[Ridge][fold 4] MAE=0.080201 RMSE=0.263954\n",
      "[Ridge][fold 5] MAE=0.075977 RMSE=0.217855\n",
      "Ridge: MAE mean=0.076928 std=0.002016 | RMSE mean=0.219648 std=0.027252\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CV: RIDGE (on processed)\n",
    "# =========================\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def cv_oof_ridge(X_proc, y_series: pd.Series, cv, alpha: float = 2.0):\n",
    "    oof = np.zeros(len(y_series), dtype=float)\n",
    "    fold_scores = []\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_proc, y_series), 1):\n",
    "        m = Ridge(alpha=alpha)\n",
    "        m.fit(X_proc[tr_idx], y_series.iloc[tr_idx])\n",
    "        pred = np.clip(m.predict(X_proc[va_idx]), 0, None)\n",
    "        oof[va_idx] = pred\n",
    "        mae = float(mean_absolute_error(y_series.iloc[va_idx], pred))\n",
    "        r = rmse(y_series.iloc[va_idx], pred)\n",
    "        fold_scores.append((mae, r))\n",
    "        print(f\"[Ridge][fold {fold}] MAE={mae:.6f} RMSE={r:.6f}\")\n",
    "    maes = np.array([s[0] for s in fold_scores])\n",
    "    rmses = np.array([s[1] for s in fold_scores])\n",
    "    print(f\"Ridge: MAE mean={maes.mean():.6f} std={maes.std():.6f} | RMSE mean={rmses.mean():.6f} std={rmses.std():.6f}\")\n",
    "    return oof, fold_scores\n",
    "\n",
    "oof_ridge, ridge_scores = cv_oof_ridge(X_train_proc, y, cv, alpha=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a29223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0821066\ttest: 0.0652163\tbest: 0.0652163 (0)\ttotal: 57.4ms\tremaining: 19m 7s\n",
      "200:\tlearn: 0.0506573\ttest: 0.0476315\tbest: 0.0476312 (199)\ttotal: 2.68s\tremaining: 4m 23s\n",
      "400:\tlearn: 0.0448817\ttest: 0.0462926\tbest: 0.0462823 (395)\ttotal: 6.54s\tremaining: 5m 19s\n",
      "600:\tlearn: 0.0414196\ttest: 0.0460048\tbest: 0.0459483 (596)\ttotal: 10.7s\tremaining: 5m 43s\n",
      "800:\tlearn: 0.0390945\ttest: 0.0460211\tbest: 0.0458778 (669)\ttotal: 13.5s\tremaining: 5m 22s\n",
      "1000:\tlearn: 0.0373430\ttest: 0.0462556\tbest: 0.0458778 (669)\ttotal: 15.7s\tremaining: 4m 58s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.04587777651\n",
      "bestIteration = 669\n",
      "\n",
      "Shrink model to first 670 iterations.\n",
      "[CatBoost][fold 1] MAE=0.045701 RMSE=0.179136 best_iter=669\n",
      "0:\tlearn: 0.0752631\ttest: 0.0916652\tbest: 0.0916652 (0)\ttotal: 11.9ms\tremaining: 3m 57s\n",
      "200:\tlearn: 0.0478139\ttest: 0.0602956\tbest: 0.0602956 (200)\ttotal: 2.16s\tremaining: 3m 33s\n",
      "400:\tlearn: 0.0421138\ttest: 0.0566446\tbest: 0.0566446 (400)\ttotal: 4.58s\tremaining: 3m 43s\n",
      "600:\tlearn: 0.0389668\ttest: 0.0556677\tbest: 0.0556677 (600)\ttotal: 6.81s\tremaining: 3m 39s\n",
      "800:\tlearn: 0.0366662\ttest: 0.0552423\tbest: 0.0552405 (799)\ttotal: 9.07s\tremaining: 3m 37s\n",
      "1000:\tlearn: 0.0350233\ttest: 0.0550153\tbest: 0.0549930 (960)\ttotal: 11.4s\tremaining: 3m 36s\n",
      "1200:\tlearn: 0.0337484\ttest: 0.0547505\tbest: 0.0547412 (1183)\ttotal: 14.1s\tremaining: 3m 41s\n",
      "1400:\tlearn: 0.0326494\ttest: 0.0545712\tbest: 0.0545712 (1400)\ttotal: 16.7s\tremaining: 3m 41s\n",
      "1600:\tlearn: 0.0317762\ttest: 0.0545329\tbest: 0.0544683 (1424)\ttotal: 18.9s\tremaining: 3m 37s\n",
      "1800:\tlearn: 0.0309085\ttest: 0.0545289\tbest: 0.0544683 (1424)\ttotal: 21.3s\tremaining: 3m 34s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05446825785\n",
      "bestIteration = 1424\n",
      "\n",
      "Shrink model to first 1425 iterations.\n",
      "[CatBoost][fold 2] MAE=0.054296 RMSE=0.222663 best_iter=1424\n",
      "0:\tlearn: 0.0794791\ttest: 0.0744687\tbest: 0.0744687 (0)\ttotal: 11ms\tremaining: 3m 40s\n",
      "200:\tlearn: 0.0494010\ttest: 0.0521408\tbest: 0.0521399 (199)\ttotal: 2.33s\tremaining: 3m 49s\n",
      "400:\tlearn: 0.0434022\ttest: 0.0509528\tbest: 0.0509415 (396)\ttotal: 4.54s\tremaining: 3m 41s\n",
      "600:\tlearn: 0.0401067\ttest: 0.0502939\tbest: 0.0502676 (590)\ttotal: 7.91s\tremaining: 4m 15s\n",
      "800:\tlearn: 0.0374992\ttest: 0.0498410\tbest: 0.0498410 (800)\ttotal: 12.1s\tremaining: 4m 49s\n",
      "1000:\tlearn: 0.0359375\ttest: 0.0497025\tbest: 0.0496840 (991)\ttotal: 15.9s\tremaining: 5m 2s\n",
      "1200:\tlearn: 0.0344307\ttest: 0.0496281\tbest: 0.0496281 (1200)\ttotal: 18.3s\tremaining: 4m 45s\n",
      "1400:\tlearn: 0.0333351\ttest: 0.0495708\tbest: 0.0495026 (1324)\ttotal: 20.8s\tremaining: 4m 36s\n",
      "1600:\tlearn: 0.0323130\ttest: 0.0495089\tbest: 0.0494017 (1494)\ttotal: 23.3s\tremaining: 4m 27s\n",
      "1800:\tlearn: 0.0315274\ttest: 0.0494709\tbest: 0.0494017 (1494)\ttotal: 25.6s\tremaining: 4m 19s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.04940168861\n",
      "bestIteration = 1494\n",
      "\n",
      "Shrink model to first 1495 iterations.\n",
      "[CatBoost][fold 3] MAE=0.049148 RMSE=0.189092 best_iter=1494\n",
      "0:\tlearn: 0.0782335\ttest: 0.0801339\tbest: 0.0801339 (0)\ttotal: 11.5ms\tremaining: 3m 50s\n",
      "200:\tlearn: 0.0479737\ttest: 0.0569260\tbest: 0.0569260 (200)\ttotal: 2.16s\tremaining: 3m 33s\n",
      "400:\tlearn: 0.0430675\ttest: 0.0557941\tbest: 0.0557899 (399)\ttotal: 4.39s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0399955\ttest: 0.0551493\tbest: 0.0551340 (595)\ttotal: 6.66s\tremaining: 3m 35s\n",
      "800:\tlearn: 0.0381101\ttest: 0.0550186\tbest: 0.0549809 (775)\ttotal: 9.03s\tremaining: 3m 36s\n",
      "1000:\tlearn: 0.0364989\ttest: 0.0547876\tbest: 0.0547876 (1000)\ttotal: 11.4s\tremaining: 3m 36s\n",
      "1200:\tlearn: 0.0353121\ttest: 0.0548248\tbest: 0.0547363 (1074)\ttotal: 14s\tremaining: 3m 38s\n",
      "1400:\tlearn: 0.0343528\ttest: 0.0548361\tbest: 0.0547363 (1074)\ttotal: 16.5s\tremaining: 3m 38s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05473625116\n",
      "bestIteration = 1074\n",
      "\n",
      "Shrink model to first 1075 iterations.\n",
      "[CatBoost][fold 4] MAE=0.054479 RMSE=0.239187 best_iter=1074\n",
      "0:\tlearn: 0.0778234\ttest: 0.0815872\tbest: 0.0815872 (0)\ttotal: 18.5ms\tremaining: 6m 10s\n",
      "200:\tlearn: 0.0485461\ttest: 0.0561577\tbest: 0.0561563 (197)\ttotal: 3.97s\tremaining: 6m 31s\n",
      "400:\tlearn: 0.0435865\ttest: 0.0554158\tbest: 0.0553575 (366)\ttotal: 8.01s\tremaining: 6m 31s\n",
      "600:\tlearn: 0.0403931\ttest: 0.0551086\tbest: 0.0550613 (531)\ttotal: 11.8s\tremaining: 6m 20s\n",
      "800:\tlearn: 0.0379644\ttest: 0.0551251\tbest: 0.0550119 (688)\ttotal: 14.1s\tremaining: 5m 38s\n",
      "1000:\tlearn: 0.0361907\ttest: 0.0552826\tbest: 0.0550119 (688)\ttotal: 16.5s\tremaining: 5m 12s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05501185961\n",
      "bestIteration = 688\n",
      "\n",
      "Shrink model to first 689 iterations.\n",
      "[CatBoost][fold 5] MAE=0.054843 RMSE=0.217501 best_iter=688\n",
      "CatBoost: MAE mean=0.051693 std=0.003656 | RMSE mean=0.209516 std=0.022168\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CV: CATBOOST (CPU only, without Name text cols)\n",
    "# =========================\n",
    "def make_catboost_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # CatBoost нормально принимает pandas.DataFrame. Для категорий лучше string + fillna.\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if str(out[c].dtype) in (\"object\", \"category\", \"string\", \"bool\"):\n",
    "            out[c] = out[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    return out\n",
    "\n",
    "def cv_oof_catboost(X_df: pd.DataFrame, y_series: pd.Series, cv):\n",
    "    # Удаляем текстовые Name фичи из CatBoost (их обрабатывает Ridge)\n",
    "    drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_df.columns]\n",
    "    X_cb = X_df.drop(columns=drop_cols).reset_index(drop=True)\n",
    "    X_cb = make_catboost_frame(X_cb)\n",
    "\n",
    "    cat_cols = X_cb.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "    cat_idx  = [X_cb.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    oof = np.zeros(len(y_series), dtype=float)\n",
    "    fold_scores = []\n",
    "    best_iters = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_cb, y_series), 1):\n",
    "        X_tr, X_va = X_cb.iloc[tr_idx], X_cb.iloc[va_idx]\n",
    "        y_tr, y_va = y_series.iloc[tr_idx], y_series.iloc[va_idx]\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"MAE\",\n",
    "            eval_metric=\"MAE\",\n",
    "            iterations=20000,\n",
    "            learning_rate=0.03,\n",
    "            depth=8,\n",
    "            l2_leaf_reg=6.0,\n",
    "            random_seed=RANDOM_STATE,\n",
    "            # CPU only (стабильнее, без требований к CUDA)\n",
    "            task_type=\"CPU\",\n",
    "            # регуляризация\n",
    "            subsample=0.8,\n",
    "            rsm=0.8,\n",
    "            bootstrap_type=\"Bernoulli\",\n",
    "            # контроль\n",
    "            verbose=200,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            cat_features=cat_idx,\n",
    "            eval_set=(X_va, y_va),\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=500,\n",
    "        )\n",
    "\n",
    "        pred = np.clip(model.predict(X_va), 0, None)\n",
    "        oof[va_idx] = pred\n",
    "\n",
    "        mae = float(mean_absolute_error(y_va, pred))\n",
    "        r = rmse(y_va, pred)\n",
    "        fold_scores.append((mae, r))\n",
    "        best_iters.append(int(model.get_best_iteration()))\n",
    "        print(f\"[CatBoost][fold {fold}] MAE={mae:.6f} RMSE={r:.6f} best_iter={best_iters[-1]}\")\n",
    "\n",
    "    maes = np.array([s[0] for s in fold_scores])\n",
    "    rmses = np.array([s[1] for s in fold_scores])\n",
    "    print(f\"CatBoost: MAE mean={maes.mean():.6f} std={maes.std():.6f} | RMSE mean={rmses.mean():.6f} std={rmses.std():.6f}\")\n",
    "\n",
    "    return oof, fold_scores, best_iters\n",
    "\n",
    "oof_cb, cb_scores, cb_best_iters = cv_oof_catboost(X_train_raw, y, cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee72f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ensemble: {'w': 1.0, 'mae': 0.05169282280828424, 'rmse': 0.21068200548958355}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ENSEMBLE WEIGHT (grid search on OOF)\n",
    "# =========================\n",
    "weights = np.linspace(0, 1, 201)  # w = доля CatBoost\n",
    "best = {\"w\": None, \"mae\": np.inf, \"rmse\": np.inf}\n",
    "\n",
    "for w in weights:\n",
    "    ens = w * oof_cb + (1 - w) * oof_ridge\n",
    "    mae = float(mean_absolute_error(y, ens))\n",
    "    r = rmse(y, ens)\n",
    "    if mae < best[\"mae\"]:\n",
    "        best = {\"w\": float(w), \"mae\": mae, \"rmse\": r}\n",
    "\n",
    "print(\"Best ensemble:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6584e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def _prep_lookup_keys(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "\n",
    "    if \"Name_norm\" in df.columns:\n",
    "        out[\"Name_norm\"] = df[\"Name_norm\"].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    else:\n",
    "        s = df[\"Name\"].astype(\"string\").fillna(\"\")\n",
    "        s = s.str.lower()\n",
    "        s = s.str.replace(r\"[\\u2122\\u00ae]\", \"\", regex=True)     # ™ ®\n",
    "        s = s.str.replace(r\"[^0-9a-z]+\", \" \", regex=True)        # латиница+цифры\n",
    "        s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "        out[\"Name_norm\"] = s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "    out[\"Platform\"] = df[\"Platform\"].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "    year = pd.to_numeric(df[\"Year_of_Release\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    out[\"Year_of_Release\"] = year\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_lookup(train_df: pd.DataFrame, y: pd.Series, key_cols, min_cnt: int = 1) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Возвращает pd.Series с MultiIndex по key_cols и значениями median(y).\n",
    "    min_cnt позволяет отфильтровать редкие ключи (полезно на fallback уровнях).\n",
    "    \"\"\"\n",
    "    keys = _prep_lookup_keys(train_df)[key_cols]\n",
    "    tmp = keys.copy()\n",
    "    tmp[\"y\"] = y.values\n",
    "\n",
    "    g = tmp.groupby(key_cols)[\"y\"].agg([\"median\", \"count\"])\n",
    "    g = g[g[\"count\"] >= min_cnt]\n",
    "    return g[\"median\"]\n",
    "\n",
    "def apply_lookup(lookup: pd.Series, df: pd.DataFrame, key_cols):\n",
    "    keys = _prep_lookup_keys(df)[key_cols]\n",
    "    mi = pd.MultiIndex.from_frame(keys)\n",
    "    pred = lookup.reindex(mi).to_numpy()\n",
    "    found = ~pd.isna(pred)\n",
    "    return pred, found\n",
    "\n",
    "def oof_lookup_pred(df: pd.DataFrame, y: pd.Series, cv, key_cols, min_cnt: int = 1):\n",
    "    \"\"\"\n",
    "    OOF-lookup: на каждом фолде строим lookup только по train-fold,\n",
    "    применяем к val-fold.\n",
    "    \"\"\"\n",
    "    oof = np.full(len(df), np.nan, dtype=float)\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(df), 1):\n",
    "        lookup = build_lookup(df.iloc[tr_idx], y.iloc[tr_idx], key_cols, min_cnt=min_cnt)\n",
    "        pred_va, found_va = apply_lookup(lookup, df.iloc[va_idx], key_cols)\n",
    "        oof[va_idx] = pred_va  # NaN там, где не найдено\n",
    "\n",
    "        cov = float(np.mean(found_va))\n",
    "        # MAE только по найденным\n",
    "        if np.any(found_va):\n",
    "            mae = mean_absolute_error(y.iloc[va_idx].values[found_va], pred_va[found_va])\n",
    "        else:\n",
    "            mae = np.nan\n",
    "        print(f\"[OOF-LOOKUP][fold {fold}] coverage={cov:.2%}, MAE(found-only)={mae}\")\n",
    "\n",
    "    return oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "569ddb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0818356\ttest: 0.0629149\tbest: 0.0629149 (0)\ttotal: 15.7ms\tremaining: 7m 51s\n",
      "200:\tlearn: 0.0677782\ttest: 0.0523368\tbest: 0.0523368 (200)\ttotal: 1.37s\tremaining: 3m 23s\n",
      "400:\tlearn: 0.0632077\ttest: 0.0509059\tbest: 0.0509059 (400)\ttotal: 2.77s\tremaining: 3m 24s\n",
      "600:\tlearn: 0.0605152\ttest: 0.0500940\tbest: 0.0500940 (600)\ttotal: 4.18s\tremaining: 3m 24s\n",
      "800:\tlearn: 0.0585654\ttest: 0.0493189\tbest: 0.0493138 (799)\ttotal: 5.7s\tremaining: 3m 27s\n",
      "1000:\tlearn: 0.0569591\ttest: 0.0487202\tbest: 0.0487202 (1000)\ttotal: 7.21s\tremaining: 3m 29s\n",
      "1200:\tlearn: 0.0551724\ttest: 0.0475071\tbest: 0.0475070 (1199)\ttotal: 8.79s\tremaining: 3m 30s\n",
      "1400:\tlearn: 0.0531650\ttest: 0.0460872\tbest: 0.0460872 (1400)\ttotal: 10.4s\tremaining: 3m 31s\n",
      "1600:\tlearn: 0.0515211\ttest: 0.0453158\tbest: 0.0453143 (1594)\ttotal: 11.9s\tremaining: 3m 31s\n",
      "1800:\tlearn: 0.0504417\ttest: 0.0448627\tbest: 0.0448627 (1800)\ttotal: 13.7s\tremaining: 3m 34s\n",
      "2000:\tlearn: 0.0496232\ttest: 0.0445564\tbest: 0.0445545 (1997)\ttotal: 15.6s\tremaining: 3m 38s\n",
      "2200:\tlearn: 0.0489196\ttest: 0.0443353\tbest: 0.0443353 (2200)\ttotal: 17.3s\tremaining: 3m 38s\n",
      "2400:\tlearn: 0.0483028\ttest: 0.0441204\tbest: 0.0441187 (2392)\ttotal: 19.3s\tremaining: 3m 42s\n",
      "2600:\tlearn: 0.0477867\ttest: 0.0439370\tbest: 0.0439370 (2600)\ttotal: 22.5s\tremaining: 3m 57s\n",
      "2800:\tlearn: 0.0473039\ttest: 0.0437571\tbest: 0.0437571 (2800)\ttotal: 25.8s\tremaining: 4m 10s\n",
      "3000:\tlearn: 0.0468986\ttest: 0.0436427\tbest: 0.0436404 (2993)\ttotal: 29.1s\tremaining: 4m 21s\n",
      "3200:\tlearn: 0.0465156\ttest: 0.0435424\tbest: 0.0435423 (3199)\ttotal: 31s\tremaining: 4m 19s\n",
      "3400:\tlearn: 0.0461372\ttest: 0.0434189\tbest: 0.0434186 (3399)\ttotal: 33s\tremaining: 4m 17s\n",
      "3600:\tlearn: 0.0458158\ttest: 0.0433542\tbest: 0.0433536 (3596)\ttotal: 35s\tremaining: 4m 16s\n",
      "3800:\tlearn: 0.0454643\ttest: 0.0432513\tbest: 0.0432513 (3800)\ttotal: 36.7s\tremaining: 4m 13s\n",
      "4000:\tlearn: 0.0451272\ttest: 0.0432098\tbest: 0.0432015 (3931)\ttotal: 38.5s\tremaining: 4m 10s\n",
      "4200:\tlearn: 0.0448001\ttest: 0.0431733\tbest: 0.0431708 (4184)\ttotal: 40.2s\tremaining: 4m 7s\n",
      "4400:\tlearn: 0.0445715\ttest: 0.0431147\tbest: 0.0431147 (4400)\ttotal: 42s\tremaining: 4m 4s\n",
      "4600:\tlearn: 0.0442373\ttest: 0.0430621\tbest: 0.0430618 (4598)\ttotal: 43.8s\tremaining: 4m 1s\n",
      "4800:\tlearn: 0.0438564\ttest: 0.0430220\tbest: 0.0430218 (4799)\ttotal: 45.5s\tremaining: 3m 58s\n",
      "5000:\tlearn: 0.0435161\ttest: 0.0429642\tbest: 0.0429613 (4993)\ttotal: 47.3s\tremaining: 3m 56s\n",
      "5200:\tlearn: 0.0431870\ttest: 0.0428937\tbest: 0.0428924 (5199)\ttotal: 49.2s\tremaining: 3m 54s\n",
      "5400:\tlearn: 0.0429076\ttest: 0.0428446\tbest: 0.0428350 (5370)\ttotal: 51.3s\tremaining: 3m 53s\n",
      "5600:\tlearn: 0.0426546\ttest: 0.0428104\tbest: 0.0427865 (5492)\ttotal: 53.2s\tremaining: 3m 51s\n",
      "5800:\tlearn: 0.0424064\ttest: 0.0427688\tbest: 0.0427589 (5740)\ttotal: 55s\tremaining: 3m 49s\n",
      "6000:\tlearn: 0.0422017\ttest: 0.0427241\tbest: 0.0427231 (5985)\ttotal: 57.7s\tremaining: 3m 50s\n",
      "6200:\tlearn: 0.0420063\ttest: 0.0427203\tbest: 0.0427126 (6198)\ttotal: 1m\tremaining: 3m 53s\n",
      "6400:\tlearn: 0.0418032\ttest: 0.0427246\tbest: 0.0427042 (6326)\ttotal: 1m 4s\tremaining: 3m 56s\n",
      "6600:\tlearn: 0.0416239\ttest: 0.0427067\tbest: 0.0427011 (6574)\ttotal: 1m 6s\tremaining: 3m 55s\n",
      "6800:\tlearn: 0.0413705\ttest: 0.0426470\tbest: 0.0426467 (6799)\ttotal: 1m 8s\tremaining: 3m 52s\n",
      "7000:\tlearn: 0.0411985\ttest: 0.0426084\tbest: 0.0426005 (6998)\ttotal: 1m 9s\tremaining: 3m 48s\n",
      "7200:\tlearn: 0.0410192\ttest: 0.0425440\tbest: 0.0425411 (7167)\ttotal: 1m 11s\tremaining: 3m 46s\n",
      "7400:\tlearn: 0.0408560\ttest: 0.0425110\tbest: 0.0425083 (7345)\ttotal: 1m 13s\tremaining: 3m 42s\n",
      "7600:\tlearn: 0.0406787\ttest: 0.0425113\tbest: 0.0424988 (7509)\ttotal: 1m 14s\tremaining: 3m 39s\n",
      "7800:\tlearn: 0.0405097\ttest: 0.0424958\tbest: 0.0424933 (7774)\ttotal: 1m 16s\tremaining: 3m 36s\n",
      "8000:\tlearn: 0.0403516\ttest: 0.0424797\tbest: 0.0424697 (7971)\ttotal: 1m 17s\tremaining: 3m 34s\n",
      "8200:\tlearn: 0.0401851\ttest: 0.0424800\tbest: 0.0424662 (8150)\ttotal: 1m 19s\tremaining: 3m 31s\n",
      "8400:\tlearn: 0.0400039\ttest: 0.0424431\tbest: 0.0424416 (8393)\ttotal: 1m 21s\tremaining: 3m 29s\n",
      "8600:\tlearn: 0.0398640\ttest: 0.0424654\tbest: 0.0424416 (8393)\ttotal: 1m 23s\tremaining: 3m 26s\n",
      "8800:\tlearn: 0.0397335\ttest: 0.0424591\tbest: 0.0424416 (8393)\ttotal: 1m 24s\tremaining: 3m 24s\n",
      "9000:\tlearn: 0.0395838\ttest: 0.0424484\tbest: 0.0424388 (8870)\ttotal: 1m 26s\tremaining: 3m 22s\n",
      "9200:\tlearn: 0.0394337\ttest: 0.0424475\tbest: 0.0424388 (8870)\ttotal: 1m 28s\tremaining: 3m 19s\n",
      "9400:\tlearn: 0.0392983\ttest: 0.0424282\tbest: 0.0424282 (9400)\ttotal: 1m 29s\tremaining: 3m 17s\n",
      "9600:\tlearn: 0.0391576\ttest: 0.0424004\tbest: 0.0423999 (9588)\ttotal: 1m 31s\tremaining: 3m 14s\n",
      "9800:\tlearn: 0.0390484\ttest: 0.0424020\tbest: 0.0423934 (9606)\ttotal: 1m 33s\tremaining: 3m 12s\n",
      "10000:\tlearn: 0.0389481\ttest: 0.0423995\tbest: 0.0423934 (9606)\ttotal: 1m 35s\tremaining: 3m 10s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.04239336633\n",
      "bestIteration = 9606\n",
      "\n",
      "Shrink model to first 9607 iterations.\n",
      "Pred stats: ridge_mean=0.0917, cb_mean=0.0531, ens_mean=0.0531, w=1.0\n",
      "Lookup L1 hit-rate: 0.02% (1/5016)\n",
      "Lookup L2 extra hit-rate: 0.00% (+0 rows)\n",
      "Final stats: ens_mean=0.0531, final_mean=0.0531\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# FINAL FIT + PREDICT TEST\n",
    "# =========================\n",
    "# Ridge final on all processed train\n",
    "ridge_final = Ridge(alpha=2.0)\n",
    "ridge_final.fit(X_train_proc, y)\n",
    "pred_ridge = np.clip(ridge_final.predict(X_test_proc), 0, None)\n",
    "\n",
    "# CatBoost final: fit with holdout for early stopping\n",
    "drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_train_raw.columns]\n",
    "X_cb_full = X_train_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "X_cb_test = X_test_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "\n",
    "X_cb_full = make_catboost_frame(X_cb_full)\n",
    "X_cb_test = make_catboost_frame(X_cb_test)\n",
    "\n",
    "cat_cols = X_cb_full.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "cat_idx  = [X_cb_full.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_cb_full, y, test_size=0.15, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "cb_final = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    eval_metric=\"MAE\",\n",
    "    iterations=30000,\n",
    "    learning_rate=0.00951435906832524,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=9.262544379661907,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    task_type=\"CPU\",\n",
    "    subsample=0.82,\n",
    "    rsm=0.9774802096909228,\n",
    "    random_strength = 7.532380708632857,\n",
    "    bootstrap_type=\"Bernoulli\",\n",
    "    min_data_in_leaf = 18,\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "cb_final.fit(\n",
    "    X_tr, y_tr,\n",
    "    cat_features=cat_idx,\n",
    "    eval_set=(X_va, y_va),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=500,\n",
    ")\n",
    "\n",
    "pred_cb = np.clip(cb_final.predict(X_cb_test), 0, None)\n",
    "\n",
    "w = best[\"w\"] if best[\"w\"] is not None else 0.5\n",
    "pred_ens = np.clip(w * pred_cb + (1 - w) * pred_ridge, 0, None)\n",
    "\n",
    "print(f\"Pred stats: ridge_mean={pred_ridge.mean():.4f}, cb_mean={pred_cb.mean():.4f}, ens_mean={pred_ens.mean():.4f}, w={w}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Ensure Name_norm exists for lookup keys ---\n",
    "if \"Name_norm\" not in X_train_raw.columns:\n",
    "    X_train_raw = X_train_raw.copy()\n",
    "    X_train_raw[\"Name_norm\"] = normalize_name(X_train_raw[\"Name\"]) if \"normalize_name\" in globals() else X_train_raw[\"Name\"].astype(\"string\")\n",
    "if \"Name_norm\" not in X_test_raw.columns:\n",
    "    X_test_raw = X_test_raw.copy()\n",
    "    X_test_raw[\"Name_norm\"] = normalize_name(X_test_raw[\"Name\"]) if \"normalize_name\" in globals() else X_test_raw[\"Name\"].astype(\"string\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# LOOKUP (train -> test)\n",
    "# =========================\n",
    "# Уровень 1: строгий ключ (Name_norm + Platform + Year)\n",
    "key1 = [\"Name_norm\", \"Platform\", \"Year_of_Release\"]\n",
    "lk1 = build_lookup(X_train_raw, y, key1, min_cnt=1)\n",
    "lk1_pred, lk1_found = apply_lookup(lk1, X_test_raw, key1)\n",
    "\n",
    "pred_final = pred_ens.copy()\n",
    "pred_final[lk1_found] = lk1_pred[lk1_found]\n",
    "\n",
    "print(f\"Lookup L1 hit-rate: {lk1_found.mean():.2%} ({lk1_found.sum()}/{len(lk1_found)})\")\n",
    "\n",
    "# (опционально) Уровень 2: fallback без года (иногда даёт сильный буст, но аккуратно)\n",
    "# Если включаете — лучше поставить min_cnt>=2, чтобы уменьшить шум.\n",
    "key2 = [\"Name_norm\", \"Platform\"]\n",
    "lk2 = build_lookup(X_train_raw, y, key2, min_cnt=2)\n",
    "lk2_pred, lk2_found = apply_lookup(lk2, X_test_raw, key2)\n",
    "\n",
    "# применяем fallback ТОЛЬКО там, где L1 не нашёлся\n",
    "need2 = (~lk1_found) & (lk2_found)\n",
    "pred_final[need2] = lk2_pred[need2]\n",
    "\n",
    "print(f\"Lookup L2 extra hit-rate: {need2.mean():.2%} (+{need2.sum()} rows)\")\n",
    "\n",
    "pred_final = np.clip(pred_final, 0, None)\n",
    "\n",
    "print(f\"Final stats: ens_mean={pred_ens.mean():.4f}, final_mean={pred_final.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f8cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>JP_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  JP_Sales\n",
       "0   1      0.07\n",
       "1   2      0.00\n",
       "2   3      0.00\n",
       "3   4      0.00\n",
       "4   5      0.00\n",
       "5   6      0.01\n",
       "6   7      0.01\n",
       "7   8      0.14\n",
       "8   9      2.78\n",
       "9  10      0.00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# SUBMISSION\n",
    "# =========================\n",
    "\n",
    "sub = pd.DataFrame({\"Id\": test_ids, \"JP_Sales\": pred_final})\n",
    "sub[\"JP_Sales\"] = sub[\"JP_Sales\"].round(2)\n",
    "\n",
    "\n",
    "sub.to_csv(\"sub_with_name_5.csv\", index=False)\n",
    "sub.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d179d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
