{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b6e234",
   "metadata": {},
   "source": [
    "# Video Games JP_Sales: исправленная версия (Name + franchise features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3728be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 11703 Test rows: 5016 All rows: 16719\n",
      "Columns: ['Name', 'Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_PATH = \"Video_Games.csv\"\n",
    "TEST_PATH  = \"Video_Games_Test.csv\"\n",
    "TARGET = \"JP_Sales\"\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# на случай \"Id \" / \" id\" / пробелов\n",
    "train_df.columns = train_df.columns.str.strip()\n",
    "test_df.columns  = test_df.columns.str.strip()\n",
    "\n",
    "assert TARGET in train_df.columns, f\"'{TARGET}' not found in train\"\n",
    "\n",
    "y = train_df[TARGET].astype(float)\n",
    "X_train_raw = train_df.drop(columns=[TARGET]).copy()\n",
    "X_test_raw  = test_df.copy()\n",
    "\n",
    "def find_id_col(df):\n",
    "    for c in df.columns:\n",
    "        if str(c).strip().lower() == \"id\":\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "id_col_train = find_id_col(X_train_raw)\n",
    "id_col_test  = find_id_col(X_test_raw)\n",
    "\n",
    "if id_col_test is not None:\n",
    "    test_ids = X_test_raw[id_col_test].values\n",
    "else:\n",
    "    test_ids = np.arange(1, len(X_test_raw) + 1)\n",
    "\n",
    "if id_col_train is not None:\n",
    "    X_train_raw.drop(columns=[id_col_train], inplace=True)\n",
    "if id_col_test is not None:\n",
    "    X_test_raw.drop(columns=[id_col_test], inplace=True)\n",
    "\n",
    "X_all = pd.concat([X_train_raw, X_test_raw], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Train rows:\", len(X_train_raw), \"Test rows:\", len(X_test_raw), \"All rows:\", len(X_all))\n",
    "print(\"Columns:\", list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b747d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Name Platform  Year_of_Release  \\\n",
      "0                      Rapala Trophies      PSP           2006.0   \n",
      "1              New Super Mario Bros. U     WiiU           2012.0   \n",
      "2                               Robots      PS2           2005.0   \n",
      "3                       Hamster Club 3      GBA           2002.0   \n",
      "4                         Formula 1 06      PS2           2006.0   \n",
      "5                     My Ballet Studio      Wii           2009.0   \n",
      "6                           EVE Online       PC           2003.0   \n",
      "7  S.T.A.L.K.E.R.: Shadow of Chernobyl       PC           2007.0   \n",
      "8                      Madden NFL 2003       XB           2002.0   \n",
      "9              Shin Super Robot Taisen       PS           1996.0   \n",
      "\n",
      "          Genre                    Publisher  NA_Sales  EU_Sales  Other_Sales  \\\n",
      "0        Sports                   Activision      0.04      0.00         0.00   \n",
      "1      Platform                     Nintendo      2.30      1.34         0.32   \n",
      "2        Action                Vivendi Games      0.18      0.14         0.05   \n",
      "3    Simulation                      Jorudan      0.00      0.00         0.01   \n",
      "4        Racing  Sony Computer Entertainment      0.00      0.00         0.00   \n",
      "5    Simulation                    505 Games      0.02      0.00         0.00   \n",
      "6  Role-Playing                          CCP      0.00      0.19         0.01   \n",
      "7       Shooter                          THQ      0.01      0.04         0.01   \n",
      "8        Sports              Electronic Arts      0.67      0.02         0.03   \n",
      "9  Role-Playing                    Banpresto      0.00      0.00         0.04   \n",
      "\n",
      "   Critic_Score  Critic_Count  User_Score  User_Count  \\\n",
      "0           NaN           NaN         NaN         NaN   \n",
      "1          84.0          70.0         8.1       733.0   \n",
      "2          53.0           6.0         6.0         8.0   \n",
      "3           NaN           NaN         NaN         NaN   \n",
      "4           NaN           NaN         NaN         NaN   \n",
      "5           NaN           NaN         NaN         NaN   \n",
      "6          69.0          22.0         7.5       280.0   \n",
      "7          82.0          44.0         8.4      1088.0   \n",
      "8          92.0          16.0         8.3        16.0   \n",
      "9           NaN           NaN         NaN         NaN   \n",
      "\n",
      "                        Developer Rating  \n",
      "0              Sand Grain Studios      E  \n",
      "1                        Nintendo      E  \n",
      "2  Eurocom Entertainment Software      E  \n",
      "3                             NaN    NaN  \n",
      "4                             NaN    NaN  \n",
      "5                       505 Games      E  \n",
      "6                             CCP      T  \n",
      "7                  GSC Game World      M  \n",
      "8                      EA Tiburon      E  \n",
      "9                             NaN    NaN  \n",
      "                            Name Platform  Year_of_Release         Genre  \\\n",
      "0   BeatMania IIDX 13: DistorteD      PS2           2007.0    Simulation   \n",
      "1         Rugrats: Castle Capers      GBA           2001.0        Action   \n",
      "2                    Overlord II      PS3           2009.0        Action   \n",
      "3  Barbie as The Island Princess      GBA           2007.0     Adventure   \n",
      "4          Petz: Hamsterz Life 2      GBA           2007.0          Misc   \n",
      "5              Rollcage Stage II       PS           2000.0        Racing   \n",
      "6                      Syndicate      PS3           2012.0       Shooter   \n",
      "7                    Sakura Wars       DC           2000.0     Adventure   \n",
      "8  Pokemon Ruby/Pokemon Sapphire      GBA           2002.0  Role-Playing   \n",
      "9   Pictionary: Ultimate Edition      PS3           2011.0          Misc   \n",
      "\n",
      "                      Publisher  NA_Sales  EU_Sales  Other_Sales  \\\n",
      "0  Konami Digital Entertainment      0.00      0.00         0.00   \n",
      "1                           THQ      0.33      0.12         0.01   \n",
      "2                   Codemasters      0.11      0.15         0.06   \n",
      "3                    Activision      0.16      0.06         0.00   \n",
      "4                       Ubisoft      0.01      0.00         0.00   \n",
      "5   Sony Computer Entertainment      0.05      0.03         0.01   \n",
      "6                      EA Games      0.07      0.06         0.02   \n",
      "7                          Sega      0.00      0.00         0.00   \n",
      "8                      Nintendo      6.06      3.90         0.50   \n",
      "9                           THQ      0.15      0.06         0.03   \n",
      "\n",
      "   Critic_Score  Critic_Count  User_Score  User_Count            Developer  \\\n",
      "0           NaN           NaN         NaN         NaN                  NaN   \n",
      "1           NaN           NaN         NaN         NaN                  NaN   \n",
      "2          72.0          42.0         7.6        24.0      Triumph Studios   \n",
      "3           NaN           NaN         NaN         NaN                  NaN   \n",
      "4           NaN           NaN         NaN         NaN                  NaN   \n",
      "5          85.0           7.0         8.9        16.0  Attention To Detail   \n",
      "6          75.0          29.0         6.5       106.0           Starbreeze   \n",
      "7           NaN           NaN         NaN         NaN                  NaN   \n",
      "8           NaN           NaN         NaN         NaN                  NaN   \n",
      "9          62.0           4.0         NaN         NaN      Page 44 Studios   \n",
      "\n",
      "  Rating  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2      T  \n",
      "3    NaN  \n",
      "4    NaN  \n",
      "5      E  \n",
      "6      M  \n",
      "7    NaN  \n",
      "8    NaN  \n",
      "9      E  \n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw.head(10))\n",
    "print(X_test_raw.head(10))\n",
    "print('*' * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc4059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all\n",
      "                                  Name Platform  Year_of_Release  \\\n",
      "0                      Rapala Trophies      PSP           2006.0   \n",
      "1              New Super Mario Bros. U     WiiU           2012.0   \n",
      "2                               Robots      PS2           2005.0   \n",
      "3                       Hamster Club 3      GBA           2002.0   \n",
      "4                         Formula 1 06      PS2           2006.0   \n",
      "5                     My Ballet Studio      Wii           2009.0   \n",
      "6                           EVE Online       PC           2003.0   \n",
      "7  S.T.A.L.K.E.R.: Shadow of Chernobyl       PC           2007.0   \n",
      "8                      Madden NFL 2003       XB           2002.0   \n",
      "9              Shin Super Robot Taisen       PS           1996.0   \n",
      "\n",
      "          Genre                    Publisher  NA_Sales  EU_Sales  Other_Sales  \\\n",
      "0        Sports                   Activision      0.04      0.00         0.00   \n",
      "1      Platform                     Nintendo      2.30      1.34         0.32   \n",
      "2        Action                Vivendi Games      0.18      0.14         0.05   \n",
      "3    Simulation                      Jorudan      0.00      0.00         0.01   \n",
      "4        Racing  Sony Computer Entertainment      0.00      0.00         0.00   \n",
      "5    Simulation                    505 Games      0.02      0.00         0.00   \n",
      "6  Role-Playing                          CCP      0.00      0.19         0.01   \n",
      "7       Shooter                          THQ      0.01      0.04         0.01   \n",
      "8        Sports              Electronic Arts      0.67      0.02         0.03   \n",
      "9  Role-Playing                    Banpresto      0.00      0.00         0.04   \n",
      "\n",
      "   Critic_Score  Critic_Count  User_Score  User_Count  \\\n",
      "0           NaN           NaN         NaN         NaN   \n",
      "1          84.0          70.0         8.1       733.0   \n",
      "2          53.0           6.0         6.0         8.0   \n",
      "3           NaN           NaN         NaN         NaN   \n",
      "4           NaN           NaN         NaN         NaN   \n",
      "5           NaN           NaN         NaN         NaN   \n",
      "6          69.0          22.0         7.5       280.0   \n",
      "7          82.0          44.0         8.4      1088.0   \n",
      "8          92.0          16.0         8.3        16.0   \n",
      "9           NaN           NaN         NaN         NaN   \n",
      "\n",
      "                        Developer Rating  \n",
      "0              Sand Grain Studios      E  \n",
      "1                        Nintendo      E  \n",
      "2  Eurocom Entertainment Software      E  \n",
      "3                             NaN    NaN  \n",
      "4                             NaN    NaN  \n",
      "5                       505 Games      E  \n",
      "6                             CCP      T  \n",
      "7                  GSC Game World      M  \n",
      "8                      EA Tiburon      E  \n",
      "9                             NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"X_all\")\n",
    "print(X_all.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3dda77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100687/2277753913.py:52: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_roman\"] = s.str.contains(ROMAN_RE, regex=True).astype(int)\n",
      "/tmp/ipykernel_100687/2277753913.py:53: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_edition_word\"] = s.str.contains(EDITION_RE, regex=True).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "EDITION_RE = re.compile(\n",
    "    r\"\\b(remaster(ed)?|hd|definitive|ultimate|complete|collector'?s|\"\n",
    "    r\"game of the year|goty|gold|deluxe|premium|special|limited|edition|\"\n",
    "    r\"director'?s cut|anniversary|bundle|collection)\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "ROMAN_RE = re.compile(r\"\\b(i{1,3}|iv|v|vi{0,3}|ix|x|xi|xii|xiii|xiv|xv)\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "def normalize_name(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\").fillna(\"__MISSING__\").str.lower()\n",
    "    # unify separators\n",
    "    s = s.str.replace(r\"[™®©]\", \"\", regex=True)\n",
    "    s = s.str.replace(r\"[\\(\\)\\[\\]\\{\\}]\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"[/:;,\\.\\!\\?\\|\\\\]\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"[-_]+\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "def split_base(s: pd.Series) -> pd.Series:\n",
    "    # base before ':' or long dash patterns (common subtitle separators)\n",
    "    s2 = s.str.replace(r\"\\s*:\\s*\", \" : \", regex=True)\n",
    "    # split on \":\" or \" - \" (keep left)\n",
    "    base = s2.str.split(r\"\\s:\\s|\\s-\\s|\\s—\\s\", n=1, expand=True)[0]\n",
    "    base = base.str.strip()\n",
    "    return base.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "def franchise_key(s: pd.Series) -> pd.Series:\n",
    "    s = s.copy()\n",
    "    s = s.str.replace(EDITION_RE, \" \", regex=True)\n",
    "    s = s.str.replace(ROMAN_RE, \" \", regex=True)\n",
    "    s = s.str.replace(r\"\\b\\d+\\b\", \" \", regex=True)          # sequel numbers / years in title\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "# usage (на X_all)\n",
    "if \"Name\" in X_all.columns:\n",
    "    X_all[\"Name_norm\"] = normalize_name(X_all[\"Name\"])\n",
    "    X_all[\"Name_base\"] = split_base(X_all[\"Name_norm\"])\n",
    "    X_all[\"Franchise_key\"] = franchise_key(X_all[\"Name_base\"])\n",
    "\n",
    "\n",
    "def add_name_flags(df):\n",
    "    s = df[\"Name_norm\"].astype(\"string\")\n",
    "    df[\"name_len\"] = s.str.len().fillna(0).astype(int)\n",
    "    df[\"name_words\"] = s.str.split().str.len().fillna(0).astype(int)\n",
    "    df[\"has_colon_or_dash\"] = s.str.contains(r\"\\s:\\s|\\s-\\s|\\s—\\s\", regex=True).astype(int)\n",
    "    df[\"has_digit\"] = s.str.contains(r\"\\d\").astype(int)\n",
    "    df[\"has_roman\"] = s.str.contains(ROMAN_RE, regex=True).astype(int)\n",
    "    df[\"has_edition_word\"] = s.str.contains(EDITION_RE, regex=True).astype(int)\n",
    "    return df\n",
    "\n",
    "if \"Name_norm\" in X_all.columns:\n",
    "    X_all = add_name_flags(X_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d026958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def add_oof_mean_count_features(\n",
    "    X: pd.DataFrame,\n",
    "    y,\n",
    "    X_test: pd.DataFrame,\n",
    "    keys,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "    alpha=5.0,          # smoothing strength; 0 = без сглаживания\n",
    "    fill_value=\"__MISSING__\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Добавляет OOF признаки:\n",
    "      - <key>__jp_mean  : OOF mean (optionally smoothed)\n",
    "      - <key>__jp_cnt   : OOF count\n",
    "    и для test — статистики по full train.\n",
    "    \"\"\"\n",
    "    if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "        y = np.asarray(y).reshape(-1)\n",
    "    else:\n",
    "        y = np.asarray(y).reshape(-1)\n",
    "\n",
    "    assert len(X) == len(y), \"X and y must have same length\"\n",
    "\n",
    "    X = X.reset_index(drop=True).copy()\n",
    "    X_test = X_test.reset_index(drop=True).copy()\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    global_mean = float(np.mean(y))\n",
    "\n",
    "    def _compute_for_key(key_col: str):\n",
    "        # гарантируем отсутствие NA в ключе\n",
    "        X[key_col] = X[key_col].astype(\"string\").fillna(fill_value)\n",
    "        X_test[key_col] = X_test[key_col].astype(\"string\").fillna(fill_value)\n",
    "\n",
    "        oof_mean = np.full(len(X), global_mean, dtype=float)\n",
    "        oof_cnt  = np.zeros(len(X), dtype=float)\n",
    "\n",
    "        for tr_idx, va_idx in kf.split(X):\n",
    "            tr_keys = X.loc[tr_idx, key_col].values\n",
    "\n",
    "            stats = (\n",
    "                pd.DataFrame({key_col: tr_keys, \"y\": y[tr_idx]})\n",
    "                .groupby(key_col)[\"y\"]\n",
    "                .agg([\"mean\", \"count\"])\n",
    "            )\n",
    "\n",
    "            va_keys = X.loc[va_idx, key_col]\n",
    "            m = va_keys.map(stats[\"mean\"])\n",
    "            c = va_keys.map(stats[\"count\"])\n",
    "\n",
    "            m = m.fillna(global_mean).astype(float).values\n",
    "            c = c.fillna(0).astype(float).values\n",
    "\n",
    "            if alpha and alpha > 0:\n",
    "                # smoothed mean: (m*c + global*alpha)/(c+alpha)\n",
    "                m = (m * c + global_mean * alpha) / (c + alpha)\n",
    "\n",
    "            oof_mean[va_idx] = m\n",
    "            oof_cnt[va_idx]  = c\n",
    "\n",
    "        # full-train stats for test\n",
    "        full_stats = (\n",
    "            pd.DataFrame({key_col: X[key_col].values, \"y\": y})\n",
    "            .groupby(key_col)[\"y\"]\n",
    "            .agg([\"mean\", \"count\"])\n",
    "        )\n",
    "\n",
    "        te_m = X_test[key_col].map(full_stats[\"mean\"]).fillna(global_mean).astype(float).values\n",
    "        te_c = X_test[key_col].map(full_stats[\"count\"]).fillna(0).astype(float).values\n",
    "        if alpha and alpha > 0:\n",
    "            te_m = (te_m * te_c + global_mean * alpha) / (te_c + alpha)\n",
    "\n",
    "        X[f\"{key_col}__jp_mean\"] = oof_mean\n",
    "        X[f\"{key_col}__jp_cnt\"]  = oof_cnt\n",
    "        X_test[f\"{key_col}__jp_mean\"] = te_m\n",
    "        X_test[f\"{key_col}__jp_cnt\"]  = te_c\n",
    "\n",
    "    for k in keys:\n",
    "        if k in X.columns and k in X_test.columns:\n",
    "            _compute_for_key(k)\n",
    "        else:\n",
    "            print(f\"SKIP '{k}': not present in both X and X_test\")\n",
    "\n",
    "    return X, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3f0f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_cols: ['Name']\n",
      "cat_cols: ['Platform', 'Genre', 'Publisher', 'Developer', 'Rating', 'Name_norm', 'Name_base', 'Franchise_key']\n",
      "num_cols: ['Year_of_Release', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'name_len', 'name_words', 'has_colon_or_dash', 'has_digit', 'has_roman', 'has_edition_word']\n",
      "NUM: 14 cols -> (16719, 14)\n",
      "CAT: 8 cols -> OHE shape (16719, 123)\n",
      "TEXT 'Name': TF-IDF shape (16719, 64589), vocab=64589\n",
      "TOTAL features: 64726\n",
      "X_train_proc: (11703, 64726) X_test_proc: (5016, 64726)\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS ON ALL DATA (train+test), THEN SPLIT BACK\n",
    "# =========================\n",
    "\n",
    "def make_ohe(min_freq: int):\n",
    "    \"\"\"Совместимость со sklearn: sparse_output (новый) vs sparse (старый).\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", min_frequency=min_freq, sparse_output=True)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", min_frequency=min_freq, sparse=True)\n",
    "\n",
    "def preprocess_all_data(\n",
    "    X_all_df: pd.DataFrame,\n",
    "    text_cols,\n",
    "    cat_cols,\n",
    "    num_cols,\n",
    "    min_freq: int = 50,\n",
    "    tfidf_max_features: int = 80000,\n",
    "):\n",
    "    mats = []\n",
    "\n",
    "    # 1) NUM\n",
    "    if len(num_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy=\"median\")\n",
    "        num_scaler = StandardScaler(with_mean=False)\n",
    "        num_data = num_scaler.fit_transform(num_imputer.fit_transform(X_all_df[num_cols]))\n",
    "        mats.append(sparse.csr_matrix(num_data))\n",
    "        print(f\"NUM: {len(num_cols)} cols -> {num_data.shape}\")\n",
    "\n",
    "    # 2) CAT (ИСПРАВЛЕНО!)\n",
    "    if len(cat_cols) > 0:\n",
    "        cat_df = X_all_df[cat_cols].fillna(\"__MISSING__\").astype(str)\n",
    "        ohe = make_ohe(min_freq)\n",
    "        cat_ohe = ohe.fit_transform(cat_df)\n",
    "        mats.append(cat_ohe.tocsr())\n",
    "        print(f\"CAT: {len(cat_cols)} cols -> OHE shape {cat_ohe.shape}\")\n",
    "\n",
    "    # 3) TEXT (TF-IDF)\n",
    "    def _flatten_1d(x):\n",
    "        arr = np.asarray(x).ravel().astype(str)\n",
    "        return np.where((arr == 'nan') | (arr == 'None') | (arr == '<NA>'), '', arr)\n",
    "\n",
    "    for c in text_cols:\n",
    "        # ИСПРАВЛЕНИЕ: fillna ПЕРЕД astype\n",
    "        text_data = X_all_df[c].fillna(\"\").astype(str).values\n",
    "        text_data = _flatten_1d(text_data.reshape(-1, 1))\n",
    "        \n",
    "        tfidf = TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=(3, 5),\n",
    "            min_df=2,\n",
    "            max_features=tfidf_max_features,\n",
    "        )\n",
    "        tfidf_mat = tfidf.fit_transform(text_data)\n",
    "        mats.append(tfidf_mat.tocsr())\n",
    "        print(f\"TEXT '{c}': TF-IDF shape {tfidf_mat.shape}, vocab={len(tfidf.vocabulary_)}\")\n",
    "\n",
    "    # stack\n",
    "    X_proc = sparse.hstack(mats, format=\"csr\")\n",
    "    print(f\"TOTAL features: {X_proc.shape[1]}\")\n",
    "    return X_proc\n",
    "\n",
    "# Выбираем колонки\n",
    "text_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_all.columns]\n",
    "\n",
    "cat_cols_all = X_all.select_dtypes(include=[\"object\", \"category\", \"bool\", \"string\"]).columns.tolist()\n",
    "cat_cols = [c for c in cat_cols_all if c not in set(text_cols)]\n",
    "\n",
    "num_cols = [c for c in X_all.columns if c not in set(cat_cols) and c not in set(text_cols)]\n",
    "\n",
    "print(\"text_cols:\", text_cols)\n",
    "print(\"cat_cols:\", cat_cols)\n",
    "print(\"num_cols:\", num_cols)\n",
    "\n",
    "X_all_proc = preprocess_all_data(\n",
    "    X_all,\n",
    "    text_cols=text_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    num_cols=num_cols,\n",
    "    min_freq=50,\n",
    "    tfidf_max_features=80000,\n",
    ")\n",
    "\n",
    "n_train = len(X_train_raw)\n",
    "X_train_proc = X_all_proc[:n_train]\n",
    "X_test_proc  = X_all_proc[n_train:]\n",
    "\n",
    "print(\"X_train_proc:\", X_train_proc.shape, \"X_test_proc:\", X_test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b090866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge][fold 1] MAE=0.075268 RMSE=0.188657\n",
      "[Ridge][fold 2] MAE=0.078290 RMSE=0.232864\n",
      "[Ridge][fold 3] MAE=0.074903 RMSE=0.194910\n",
      "[Ridge][fold 4] MAE=0.080201 RMSE=0.263954\n",
      "[Ridge][fold 5] MAE=0.075977 RMSE=0.217855\n",
      "Ridge: MAE mean=0.076928 std=0.002016 | RMSE mean=0.219648 std=0.027252\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CV: RIDGE (on processed)\n",
    "# =========================\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def cv_oof_ridge(X_proc, y_series: pd.Series, cv, alpha: float = 2.0):\n",
    "    oof = np.zeros(len(y_series), dtype=float)\n",
    "    fold_scores = []\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_proc, y_series), 1):\n",
    "        m = Ridge(alpha=alpha)\n",
    "        m.fit(X_proc[tr_idx], y_series.iloc[tr_idx])\n",
    "        pred = np.clip(m.predict(X_proc[va_idx]), 0, None)\n",
    "        oof[va_idx] = pred\n",
    "        mae = float(mean_absolute_error(y_series.iloc[va_idx], pred))\n",
    "        r = rmse(y_series.iloc[va_idx], pred)\n",
    "        fold_scores.append((mae, r))\n",
    "        print(f\"[Ridge][fold {fold}] MAE={mae:.6f} RMSE={r:.6f}\")\n",
    "    maes = np.array([s[0] for s in fold_scores])\n",
    "    rmses = np.array([s[1] for s in fold_scores])\n",
    "    print(f\"Ridge: MAE mean={maes.mean():.6f} std={maes.std():.6f} | RMSE mean={rmses.mean():.6f} std={rmses.std():.6f}\")\n",
    "    return oof, fold_scores\n",
    "\n",
    "oof_ridge, ridge_scores = cv_oof_ridge(X_train_proc, y, cv, alpha=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a29223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0821066\ttest: 0.0652163\tbest: 0.0652163 (0)\ttotal: 55.1ms\tremaining: 18m 22s\n",
      "200:\tlearn: 0.0506573\ttest: 0.0476315\tbest: 0.0476312 (199)\ttotal: 2.19s\tremaining: 3m 35s\n",
      "400:\tlearn: 0.0448817\ttest: 0.0462926\tbest: 0.0462823 (395)\ttotal: 4.61s\tremaining: 3m 45s\n",
      "600:\tlearn: 0.0414196\ttest: 0.0460048\tbest: 0.0459483 (596)\ttotal: 7.09s\tremaining: 3m 49s\n",
      "800:\tlearn: 0.0390945\ttest: 0.0460211\tbest: 0.0458778 (669)\ttotal: 10.9s\tremaining: 4m 20s\n",
      "1000:\tlearn: 0.0373430\ttest: 0.0462556\tbest: 0.0458778 (669)\ttotal: 14.9s\tremaining: 4m 42s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.04587777651\n",
      "bestIteration = 669\n",
      "\n",
      "Shrink model to first 670 iterations.\n",
      "[CatBoost][fold 1] MAE=0.045701 RMSE=0.179136 best_iter=669\n",
      "0:\tlearn: 0.0752631\ttest: 0.0916652\tbest: 0.0916652 (0)\ttotal: 12.5ms\tremaining: 4m 10s\n",
      "200:\tlearn: 0.0478139\ttest: 0.0602956\tbest: 0.0602956 (200)\ttotal: 2.45s\tremaining: 4m\n",
      "400:\tlearn: 0.0421138\ttest: 0.0566446\tbest: 0.0566446 (400)\ttotal: 5.17s\tremaining: 4m 12s\n",
      "600:\tlearn: 0.0389668\ttest: 0.0556677\tbest: 0.0556677 (600)\ttotal: 7.63s\tremaining: 4m 6s\n",
      "800:\tlearn: 0.0366662\ttest: 0.0552423\tbest: 0.0552405 (799)\ttotal: 9.95s\tremaining: 3m 58s\n",
      "1000:\tlearn: 0.0350233\ttest: 0.0550153\tbest: 0.0549930 (960)\ttotal: 12.4s\tremaining: 3m 56s\n",
      "1200:\tlearn: 0.0337484\ttest: 0.0547505\tbest: 0.0547412 (1183)\ttotal: 14.8s\tremaining: 3m 51s\n",
      "1400:\tlearn: 0.0326494\ttest: 0.0545712\tbest: 0.0545712 (1400)\ttotal: 17s\tremaining: 3m 45s\n",
      "1600:\tlearn: 0.0317762\ttest: 0.0545329\tbest: 0.0544683 (1424)\ttotal: 19.3s\tremaining: 3m 41s\n",
      "1800:\tlearn: 0.0309085\ttest: 0.0545289\tbest: 0.0544683 (1424)\ttotal: 21.6s\tremaining: 3m 38s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05446825785\n",
      "bestIteration = 1424\n",
      "\n",
      "Shrink model to first 1425 iterations.\n",
      "[CatBoost][fold 2] MAE=0.054296 RMSE=0.222663 best_iter=1424\n",
      "0:\tlearn: 0.0794791\ttest: 0.0744687\tbest: 0.0744687 (0)\ttotal: 11.1ms\tremaining: 3m 41s\n",
      "200:\tlearn: 0.0494010\ttest: 0.0521408\tbest: 0.0521399 (199)\ttotal: 2.11s\tremaining: 3m 28s\n",
      "400:\tlearn: 0.0434022\ttest: 0.0509528\tbest: 0.0509415 (396)\ttotal: 4.33s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.0401067\ttest: 0.0502939\tbest: 0.0502676 (590)\ttotal: 6.54s\tremaining: 3m 31s\n",
      "800:\tlearn: 0.0374992\ttest: 0.0498410\tbest: 0.0498410 (800)\ttotal: 8.78s\tremaining: 3m 30s\n",
      "1000:\tlearn: 0.0359375\ttest: 0.0497025\tbest: 0.0496840 (991)\ttotal: 11s\tremaining: 3m 29s\n",
      "1200:\tlearn: 0.0344307\ttest: 0.0496281\tbest: 0.0496281 (1200)\ttotal: 13.4s\tremaining: 3m 30s\n",
      "1400:\tlearn: 0.0333351\ttest: 0.0495708\tbest: 0.0495026 (1324)\ttotal: 15.8s\tremaining: 3m 30s\n",
      "1600:\tlearn: 0.0323130\ttest: 0.0495089\tbest: 0.0494017 (1494)\ttotal: 18.1s\tremaining: 3m 28s\n",
      "1800:\tlearn: 0.0315274\ttest: 0.0494709\tbest: 0.0494017 (1494)\ttotal: 20.5s\tremaining: 3m 27s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.04940168861\n",
      "bestIteration = 1494\n",
      "\n",
      "Shrink model to first 1495 iterations.\n",
      "[CatBoost][fold 3] MAE=0.049148 RMSE=0.189092 best_iter=1494\n",
      "0:\tlearn: 0.0782335\ttest: 0.0801339\tbest: 0.0801339 (0)\ttotal: 11ms\tremaining: 3m 40s\n",
      "200:\tlearn: 0.0479737\ttest: 0.0569260\tbest: 0.0569260 (200)\ttotal: 2.29s\tremaining: 3m 45s\n",
      "400:\tlearn: 0.0430675\ttest: 0.0557941\tbest: 0.0557899 (399)\ttotal: 6.37s\tremaining: 5m 11s\n",
      "600:\tlearn: 0.0399955\ttest: 0.0551493\tbest: 0.0551340 (595)\ttotal: 10.2s\tremaining: 5m 28s\n",
      "800:\tlearn: 0.0381101\ttest: 0.0550186\tbest: 0.0549809 (775)\ttotal: 12.4s\tremaining: 4m 57s\n",
      "1000:\tlearn: 0.0364989\ttest: 0.0547876\tbest: 0.0547876 (1000)\ttotal: 14.7s\tremaining: 4m 39s\n",
      "1200:\tlearn: 0.0353121\ttest: 0.0548248\tbest: 0.0547363 (1074)\ttotal: 17s\tremaining: 4m 25s\n",
      "1400:\tlearn: 0.0343528\ttest: 0.0548361\tbest: 0.0547363 (1074)\ttotal: 19.2s\tremaining: 4m 15s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05473625116\n",
      "bestIteration = 1074\n",
      "\n",
      "Shrink model to first 1075 iterations.\n",
      "[CatBoost][fold 4] MAE=0.054479 RMSE=0.239187 best_iter=1074\n",
      "0:\tlearn: 0.0778234\ttest: 0.0815872\tbest: 0.0815872 (0)\ttotal: 10.4ms\tremaining: 3m 27s\n",
      "200:\tlearn: 0.0485461\ttest: 0.0561577\tbest: 0.0561563 (197)\ttotal: 2.1s\tremaining: 3m 27s\n",
      "400:\tlearn: 0.0435865\ttest: 0.0554158\tbest: 0.0553575 (366)\ttotal: 4.25s\tremaining: 3m 27s\n",
      "600:\tlearn: 0.0403931\ttest: 0.0551086\tbest: 0.0550613 (531)\ttotal: 6.46s\tremaining: 3m 28s\n",
      "800:\tlearn: 0.0379644\ttest: 0.0551251\tbest: 0.0550119 (688)\ttotal: 8.66s\tremaining: 3m 27s\n",
      "1000:\tlearn: 0.0361907\ttest: 0.0552826\tbest: 0.0550119 (688)\ttotal: 10.9s\tremaining: 3m 26s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05501185961\n",
      "bestIteration = 688\n",
      "\n",
      "Shrink model to first 689 iterations.\n",
      "[CatBoost][fold 5] MAE=0.054843 RMSE=0.217501 best_iter=688\n",
      "CatBoost: MAE mean=0.051693 std=0.003656 | RMSE mean=0.209516 std=0.022168\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CV: CATBOOST (CPU only, without Name text cols)\n",
    "# =========================\n",
    "def make_catboost_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # CatBoost нормально принимает pandas.DataFrame. Для категорий лучше string + fillna.\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if str(out[c].dtype) in (\"object\", \"category\", \"string\", \"bool\"):\n",
    "            out[c] = out[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    return out\n",
    "\n",
    "def cv_oof_catboost(X_df: pd.DataFrame, y_series: pd.Series, cv):\n",
    "    # Удаляем текстовые Name фичи из CatBoost (их обрабатывает Ridge)\n",
    "    drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_df.columns]\n",
    "    X_cb = X_df.drop(columns=drop_cols).reset_index(drop=True)\n",
    "    X_cb = make_catboost_frame(X_cb)\n",
    "\n",
    "    cat_cols = X_cb.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "    cat_idx  = [X_cb.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    oof = np.zeros(len(y_series), dtype=float)\n",
    "    fold_scores = []\n",
    "    best_iters = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_cb, y_series), 1):\n",
    "        X_tr, X_va = X_cb.iloc[tr_idx], X_cb.iloc[va_idx]\n",
    "        y_tr, y_va = y_series.iloc[tr_idx], y_series.iloc[va_idx]\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"MAE\",\n",
    "            eval_metric=\"MAE\",\n",
    "            iterations=20000,\n",
    "            learning_rate=0.03,\n",
    "            depth=8,\n",
    "            l2_leaf_reg=6.0,\n",
    "            random_seed=RANDOM_STATE,\n",
    "            # CPU only (стабильнее, без требований к CUDA)\n",
    "            task_type=\"CPU\",\n",
    "            # регуляризация\n",
    "            subsample=0.8,\n",
    "            rsm=0.8,\n",
    "            bootstrap_type=\"Bernoulli\",\n",
    "            # контроль\n",
    "            verbose=200,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            cat_features=cat_idx,\n",
    "            eval_set=(X_va, y_va),\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=500,\n",
    "        )\n",
    "\n",
    "        pred = np.clip(model.predict(X_va), 0, None)\n",
    "        oof[va_idx] = pred\n",
    "\n",
    "        mae = float(mean_absolute_error(y_va, pred))\n",
    "        r = rmse(y_va, pred)\n",
    "        fold_scores.append((mae, r))\n",
    "        best_iters.append(int(model.get_best_iteration()))\n",
    "        print(f\"[CatBoost][fold {fold}] MAE={mae:.6f} RMSE={r:.6f} best_iter={best_iters[-1]}\")\n",
    "\n",
    "    maes = np.array([s[0] for s in fold_scores])\n",
    "    rmses = np.array([s[1] for s in fold_scores])\n",
    "    print(f\"CatBoost: MAE mean={maes.mean():.6f} std={maes.std():.6f} | RMSE mean={rmses.mean():.6f} std={rmses.std():.6f}\")\n",
    "\n",
    "    return oof, fold_scores, best_iters\n",
    "\n",
    "oof_cb, cb_scores, cb_best_iters = cv_oof_catboost(X_train_raw, y, cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee72f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ensemble: {'w': 1.0, 'mae': 0.05169282280828424, 'rmse': 0.21068200548958355}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ENSEMBLE WEIGHT (grid search on OOF)\n",
    "# =========================\n",
    "weights = np.linspace(0, 1, 201)  # w = доля CatBoost\n",
    "best = {\"w\": None, \"mae\": np.inf, \"rmse\": np.inf}\n",
    "\n",
    "for w in weights:\n",
    "    ens = w * oof_cb + (1 - w) * oof_ridge\n",
    "    mae = float(mean_absolute_error(y, ens))\n",
    "    r = rmse(y, ens)\n",
    "    if mae < best[\"mae\"]:\n",
    "        best = {\"w\": float(w), \"mae\": mae, \"rmse\": r}\n",
    "\n",
    "print(\"Best ensemble:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "569ddb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0813002\ttest: 0.0625222\tbest: 0.0625222 (0)\ttotal: 28.8ms\tremaining: 14m 23s\n",
      "200:\tlearn: 0.0495531\ttest: 0.0453115\tbest: 0.0453115 (200)\ttotal: 2.25s\tremaining: 5m 34s\n",
      "400:\tlearn: 0.0441989\ttest: 0.0439883\tbest: 0.0439749 (398)\ttotal: 4.49s\tremaining: 5m 31s\n",
      "600:\tlearn: 0.0410714\ttest: 0.0435741\tbest: 0.0435383 (592)\ttotal: 6.83s\tremaining: 5m 34s\n",
      "800:\tlearn: 0.0388561\ttest: 0.0434920\tbest: 0.0434107 (762)\ttotal: 9.11s\tremaining: 5m 31s\n",
      "1000:\tlearn: 0.0371144\ttest: 0.0434901\tbest: 0.0434107 (762)\ttotal: 11.4s\tremaining: 5m 30s\n",
      "1200:\tlearn: 0.0358232\ttest: 0.0434639\tbest: 0.0433869 (1136)\ttotal: 13.7s\tremaining: 5m 29s\n",
      "1400:\tlearn: 0.0345856\ttest: 0.0432990\tbest: 0.0432972 (1399)\ttotal: 16.1s\tremaining: 5m 28s\n",
      "1600:\tlearn: 0.0336457\ttest: 0.0431706\tbest: 0.0431656 (1578)\ttotal: 18.4s\tremaining: 5m 27s\n",
      "1800:\tlearn: 0.0327350\ttest: 0.0430233\tbest: 0.0430156 (1731)\ttotal: 20.8s\tremaining: 5m 25s\n",
      "2000:\tlearn: 0.0320434\ttest: 0.0431308\tbest: 0.0430156 (1731)\ttotal: 23.2s\tremaining: 5m 24s\n",
      "2200:\tlearn: 0.0314954\ttest: 0.0430724\tbest: 0.0430156 (1731)\ttotal: 25.5s\tremaining: 5m 21s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.04301561047\n",
      "bestIteration = 1731\n",
      "\n",
      "Shrink model to first 1732 iterations.\n",
      "Pred stats: ridge_mean=0.0917, cb_mean=0.0556, ens_mean=0.0556, w=1.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# FINAL FIT + PREDICT TEST\n",
    "# =========================\n",
    "# Ridge final on all processed train\n",
    "ridge_final = Ridge(alpha=2.0)\n",
    "ridge_final.fit(X_train_proc, y)\n",
    "pred_ridge = np.clip(ridge_final.predict(X_test_proc), 0, None)\n",
    "\n",
    "# CatBoost final: fit with holdout for early stopping\n",
    "drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_train_raw.columns]\n",
    "X_cb_full = X_train_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "X_cb_test = X_test_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "\n",
    "X_cb_full = make_catboost_frame(X_cb_full)\n",
    "X_cb_test = make_catboost_frame(X_cb_test)\n",
    "\n",
    "cat_cols = X_cb_full.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "cat_idx  = [X_cb_full.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_cb_full, y, test_size=0.15, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "cb_final = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    eval_metric=\"MAE\",\n",
    "    iterations=30000,\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=6.0,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    task_type=\"CPU\",\n",
    "    subsample=0.8,\n",
    "    rsm=0.8,\n",
    "    bootstrap_type=\"Bernoulli\",\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "cb_final.fit(\n",
    "    X_tr, y_tr,\n",
    "    cat_features=cat_idx,\n",
    "    eval_set=(X_va, y_va),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=500,\n",
    ")\n",
    "\n",
    "pred_cb = np.clip(cb_final.predict(X_cb_test), 0, None)\n",
    "\n",
    "w = best[\"w\"] if best[\"w\"] is not None else 0.5\n",
    "pred_ens = np.clip(w * pred_cb + (1 - w) * pred_ridge, 0, None)\n",
    "\n",
    "print(f\"Pred stats: ridge_mean={pred_ridge.mean():.4f}, cb_mean={pred_cb.mean():.4f}, ens_mean={pred_ens.mean():.4f}, w={w}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_hyperopt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-05 21:11:22,665] Using an existing study with name 'catboost_jp_sales' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna optimization: 2000 trials\n",
      "Best params will be saved to 'optuna_best_params.json' every 10 minutes\n",
      "Study stored in 'catboost_jp_sales.db' (can resume if interrupted)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# OPTUNA HYPERPARAMETER TUNING (для мощного сервера)\n",
    "# =========================\n",
    "import optuna\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Файл для сохранения лучших параметров\n",
    "BEST_PARAMS_FILE = \"optuna_best_params.json\"\n",
    "STUDY_NAME = \"catboost_jp_sales\"\n",
    "N_TRIALS = 2000  # Увеличьте для более тщательного поиска\n",
    "SAVE_INTERVAL_SEC = 600  # 10 минут\n",
    "\n",
    "# Глобальные переменные для отслеживания времени\n",
    "last_save_time = time.time()\n",
    "\n",
    "def save_best_params(study, trial=None):\n",
    "    \"\"\"Сохраняет лучшие параметры в JSON.\"\"\"\n",
    "    global last_save_time\n",
    "    \n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Сохраняем каждые 10 минут или при завершении trial\n",
    "    if current_time - last_save_time >= SAVE_INTERVAL_SEC or trial is None:\n",
    "        if study.best_trial is not None:\n",
    "            result = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"best_value\": study.best_value,\n",
    "                \"best_params\": study.best_params,\n",
    "                \"n_trials_completed\": len(study.trials),\n",
    "                \"best_trial_number\": study.best_trial.number,\n",
    "            }\n",
    "            \n",
    "            with open(BEST_PARAMS_FILE, 'w') as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "            \n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Saved best params: MAE={study.best_value:.6f}\")\n",
    "            last_save_time = current_time\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Функция оптимизации для Optuna.\"\"\"\n",
    "    \n",
    "    # Сначала выбираем тип bootstrap\n",
    "    bootstrap_type = trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS'])\n",
    "    \n",
    "    # Базовые гиперпараметры\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.15, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 20.0),\n",
    "        'rsm': trial.suggest_float('rsm', 0.5, 1.0),  # colsample_bylevel\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 50),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.0, 10.0),\n",
    "        'bootstrap_type': bootstrap_type,\n",
    "    }\n",
    "    \n",
    "    # Параметры, зависящие от типа bootstrap\n",
    "    if bootstrap_type == 'Bayesian':\n",
    "        # Bayesian использует bagging_temperature, НЕ subsample\n",
    "        params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0.0, 5.0)\n",
    "    elif bootstrap_type in ['Bernoulli', 'MVS']:\n",
    "        # Bernoulli/MVS используют subsample, НЕ bagging_temperature\n",
    "        params['subsample'] = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    \n",
    "    # Подготовка данных (как в основном коде)\n",
    "    drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_train_raw.columns]\n",
    "    X_cb = X_train_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "    X_cb = make_catboost_frame(X_cb)\n",
    "    \n",
    "    cat_cols = X_cb.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "    cat_idx  = [X_cb.columns.get_loc(c) for c in cat_cols]\n",
    "    \n",
    "    # CV для оценки\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv_inner.split(X_cb), 1):\n",
    "        X_tr, X_va = X_cb.iloc[tr_idx], X_cb.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        \n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"MAE\",\n",
    "            eval_metric=\"MAE\",\n",
    "            iterations=10000,\n",
    "            **params,\n",
    "            random_seed=RANDOM_STATE,\n",
    "            task_type=\"CPU\",\n",
    "            verbose=0,\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            cat_features=cat_idx,\n",
    "            eval_set=(X_va, y_va),\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=200,\n",
    "        )\n",
    "        \n",
    "        pred = np.clip(model.predict(X_va), 0, None)\n",
    "        mae = float(mean_absolute_error(y_va, pred))\n",
    "        fold_maes.append(mae)\n",
    "        \n",
    "        trial.report(np.mean(fold_maes), fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return np.mean(fold_maes)\n",
    "\n",
    "# Создаём study с возможностью продолжения\n",
    "storage = f\"sqlite:///{STUDY_NAME}.db\"\n",
    "sampler = TPESampler(seed=RANDOM_STATE)\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=2)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=storage,\n",
    "    load_if_exists=True,  # Продолжить если прервано\n",
    "    direction=\"minimize\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    ")\n",
    "\n",
    "print(f\"Starting Optuna optimization: {N_TRIALS} trials\")\n",
    "print(f\"Best params will be saved to '{BEST_PARAMS_FILE}' every {SAVE_INTERVAL_SEC//60} minutes\")\n",
    "print(f\"Study stored in '{STUDY_NAME}.db' (can resume if interrupted)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Запуск оптимизации с callback\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=N_TRIALS,\n",
    "    callbacks=[save_best_params],\n",
    "    show_progress_bar=True,\n",
    "    timeout= 600,\n",
    ")\n",
    "\n",
    "# Финальное сохранение\n",
    "save_best_params(study)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(f\"Best MAE: {study.best_value:.6f}\")\n",
    "print(f\"Best params: {json.dumps(study.best_params, indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA\n",
    "# =========================\n",
    "try:\n",
    "    import optuna.visualization as vis\n",
    "    \n",
    "    # История оптимизации\n",
    "    fig1 = vis.plot_optimization_history(study)\n",
    "    fig1.show()\n",
    "    \n",
    "    # Важность параметров\n",
    "    fig2 = vis.plot_param_importances(study)\n",
    "    fig2.show()\n",
    "    \n",
    "    # Slice plot\n",
    "    fig3 = vis.plot_slice(study)\n",
    "    fig3.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Install plotly for visualizations: pip install plotly\")\n",
    "    print(\"\\nTop 10 trials:\")\n",
    "    trials_df = study.trials_dataframe()\n",
    "    print(trials_df.nsmallest(10, 'value')[['number', 'value', 'params_learning_rate', 'params_depth', 'params_l2_leaf_reg']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_final_train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ФИНАЛЬНОЕ ОБУЧЕНИЕ С ЛУЧШИМИ ПАРАМЕТРАМИ\n",
    "# =========================\n",
    "\n",
    "# Загружаем лучшие параметры из файла или study\n",
    "if os.path.exists(BEST_PARAMS_FILE):\n",
    "    with open(BEST_PARAMS_FILE, 'r') as f:\n",
    "        saved_result = json.load(f)\n",
    "    best_params = saved_result['best_params']\n",
    "    print(f\"Loaded best params from {BEST_PARAMS_FILE}\")\n",
    "else:\n",
    "    best_params = study.best_params\n",
    "    print(\"Using params from study object\")\n",
    "\n",
    "print(f\"Best params: {json.dumps(best_params, indent=2)}\")\n",
    "\n",
    "# Подготовка данных\n",
    "drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_train_raw.columns]\n",
    "X_cb_full = X_train_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "X_cb_test = X_test_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "\n",
    "X_cb_full = make_catboost_frame(X_cb_full)\n",
    "X_cb_test = make_catboost_frame(X_cb_test)\n",
    "\n",
    "cat_cols = X_cb_full.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "cat_idx  = [X_cb_full.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_cb_full, y, test_size=0.15, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Финальная модель с найденными параметрами\n",
    "cb_optuna_final = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    eval_metric=\"MAE\",\n",
    "    iterations=30000,  # Больше итераций для финала\n",
    "    **best_params,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    task_type=\"CPU\",\n",
    "    bootstrap_type=\"Bayesian\" if best_params.get('bagging_temperature', 0) > 0 else \"Bernoulli\",\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "cb_optuna_final.fit(\n",
    "    X_tr, y_tr,\n",
    "    cat_features=cat_idx,\n",
    "    eval_set=(X_va, y_va),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=500,\n",
    ")\n",
    "\n",
    "pred_cb_optuna = np.clip(cb_optuna_final.predict(X_cb_test), 0, None)\n",
    "\n",
    "# Ensemble с Ridge\n",
    "w = best[\"w\"] if best[\"w\"] is not None else 0.5\n",
    "pred_ens_optuna = np.clip(w * pred_cb_optuna + (1 - w) * pred_ridge, 0, None)\n",
    "\n",
    "print(f\"\\nPred stats: cb_mean={pred_cb_optuna.mean():.4f}, ens_mean={pred_ens_optuna.mean():.4f}, w={w}\")\n",
    "\n",
    "# Сохраняем submission\n",
    "sub_optuna = pd.DataFrame({\"Id\": test_ids, \"JP_Sales\": pred_ens_optuna})\n",
    "sub_optuna.to_csv(\"sub_optuna.csv\", index=False)\n",
    "print(\"Saved submission to sub_optuna.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SUBMISSION\n",
    "# =========================\n",
    "sub = pd.DataFrame({\"Id\": test_ids, \"JP_Sales\": pred_ens})\n",
    "sub.to_csv(\"sub_with_name.csv\", index=False)\n",
    "sub.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
