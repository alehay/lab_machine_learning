{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b6e234",
   "metadata": {},
   "source": [
    "# Video Games JP_Sales: исправленная версия (Name + franchise features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3728be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 16719 Test rows: 5016 All rows: 21735\n",
      "Columns: ['Name', 'Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Global_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_PATH = \"external.csv\"\n",
    "TEST_PATH  = \"Video_Games_Test.csv\"\n",
    "TARGET = \"JP_Sales\"\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# на случай \"Id \" / \" id\" / пробелов\n",
    "train_df.columns = train_df.columns.str.strip()\n",
    "test_df.columns  = test_df.columns.str.strip()\n",
    "\n",
    "assert TARGET in train_df.columns, f\"'{TARGET}' not found in train\"\n",
    "\n",
    "y = train_df[TARGET].astype(float)\n",
    "X_train_raw = train_df.drop(columns=[TARGET]).copy()\n",
    "X_test_raw  = test_df.copy()\n",
    "\n",
    "def find_id_col(df):\n",
    "    for c in df.columns:\n",
    "        if str(c).strip().lower() == \"id\":\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "id_col_train = find_id_col(X_train_raw)\n",
    "id_col_test  = find_id_col(X_test_raw)\n",
    "\n",
    "if id_col_test is not None:\n",
    "    test_ids = X_test_raw[id_col_test].values\n",
    "else:\n",
    "    test_ids = np.arange(1, len(X_test_raw) + 1)\n",
    "\n",
    "if id_col_train is not None:\n",
    "    X_train_raw.drop(columns=[id_col_train], inplace=True)\n",
    "if id_col_test is not None:\n",
    "    X_test_raw.drop(columns=[id_col_test], inplace=True)\n",
    "\n",
    "X_all = pd.concat([X_train_raw, X_test_raw], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Train rows:\", len(X_train_raw), \"Test rows:\", len(X_test_raw), \"All rows:\", len(X_all))\n",
    "print(\"Columns:\", list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b747d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Name Platform  Year_of_Release         Genre  \\\n",
      "0                 Wii Sports      Wii           2006.0        Sports   \n",
      "1          Super Mario Bros.      NES           1985.0      Platform   \n",
      "2             Mario Kart Wii      Wii           2008.0        Racing   \n",
      "3          Wii Sports Resort      Wii           2009.0        Sports   \n",
      "4   Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing   \n",
      "5                     Tetris       GB           1989.0        Puzzle   \n",
      "6      New Super Mario Bros.       DS           2006.0      Platform   \n",
      "7                   Wii Play      Wii           2006.0          Misc   \n",
      "8  New Super Mario Bros. Wii      Wii           2009.0      Platform   \n",
      "9                  Duck Hunt      NES           1984.0       Shooter   \n",
      "\n",
      "  Publisher  NA_Sales  EU_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
      "0  Nintendo     41.36     28.96         8.45         82.53          76.0   \n",
      "1  Nintendo     29.08      3.58         0.77         40.24           NaN   \n",
      "2  Nintendo     15.68     12.76         3.29         35.52          82.0   \n",
      "3  Nintendo     15.61     10.93         2.95         32.77          80.0   \n",
      "4  Nintendo     11.27      8.89         1.00         31.37           NaN   \n",
      "5  Nintendo     23.20      2.26         0.58         30.26           NaN   \n",
      "6  Nintendo     11.28      9.14         2.88         29.80          89.0   \n",
      "7  Nintendo     13.96      9.18         2.84         28.92          58.0   \n",
      "8  Nintendo     14.44      6.94         2.24         28.32          87.0   \n",
      "9  Nintendo     26.93      0.63         0.47         28.31           NaN   \n",
      "\n",
      "   Critic_Count User_Score  User_Count Developer Rating  \n",
      "0          51.0          8       322.0  Nintendo      E  \n",
      "1           NaN        NaN         NaN       NaN    NaN  \n",
      "2          73.0        8.3       709.0  Nintendo      E  \n",
      "3          73.0          8       192.0  Nintendo      E  \n",
      "4           NaN        NaN         NaN       NaN    NaN  \n",
      "5           NaN        NaN         NaN       NaN    NaN  \n",
      "6          65.0        8.5       431.0  Nintendo      E  \n",
      "7          41.0        6.6       129.0  Nintendo      E  \n",
      "8          80.0        8.4       594.0  Nintendo      E  \n",
      "9           NaN        NaN         NaN       NaN    NaN  \n",
      "                            Name Platform  Year_of_Release         Genre  \\\n",
      "0   BeatMania IIDX 13: DistorteD      PS2           2007.0    Simulation   \n",
      "1         Rugrats: Castle Capers      GBA           2001.0        Action   \n",
      "2                    Overlord II      PS3           2009.0        Action   \n",
      "3  Barbie as The Island Princess      GBA           2007.0     Adventure   \n",
      "4          Petz: Hamsterz Life 2      GBA           2007.0          Misc   \n",
      "5              Rollcage Stage II       PS           2000.0        Racing   \n",
      "6                      Syndicate      PS3           2012.0       Shooter   \n",
      "7                    Sakura Wars       DC           2000.0     Adventure   \n",
      "8  Pokemon Ruby/Pokemon Sapphire      GBA           2002.0  Role-Playing   \n",
      "9   Pictionary: Ultimate Edition      PS3           2011.0          Misc   \n",
      "\n",
      "                      Publisher  NA_Sales  EU_Sales  Other_Sales  \\\n",
      "0  Konami Digital Entertainment      0.00      0.00         0.00   \n",
      "1                           THQ      0.33      0.12         0.01   \n",
      "2                   Codemasters      0.11      0.15         0.06   \n",
      "3                    Activision      0.16      0.06         0.00   \n",
      "4                       Ubisoft      0.01      0.00         0.00   \n",
      "5   Sony Computer Entertainment      0.05      0.03         0.01   \n",
      "6                      EA Games      0.07      0.06         0.02   \n",
      "7                          Sega      0.00      0.00         0.00   \n",
      "8                      Nintendo      6.06      3.90         0.50   \n",
      "9                           THQ      0.15      0.06         0.03   \n",
      "\n",
      "   Critic_Score  Critic_Count  User_Score  User_Count            Developer  \\\n",
      "0           NaN           NaN         NaN         NaN                  NaN   \n",
      "1           NaN           NaN         NaN         NaN                  NaN   \n",
      "2          72.0          42.0         7.6        24.0      Triumph Studios   \n",
      "3           NaN           NaN         NaN         NaN                  NaN   \n",
      "4           NaN           NaN         NaN         NaN                  NaN   \n",
      "5          85.0           7.0         8.9        16.0  Attention To Detail   \n",
      "6          75.0          29.0         6.5       106.0           Starbreeze   \n",
      "7           NaN           NaN         NaN         NaN                  NaN   \n",
      "8           NaN           NaN         NaN         NaN                  NaN   \n",
      "9          62.0           4.0         NaN         NaN      Page 44 Studios   \n",
      "\n",
      "  Rating  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2      T  \n",
      "3    NaN  \n",
      "4    NaN  \n",
      "5      E  \n",
      "6      M  \n",
      "7    NaN  \n",
      "8    NaN  \n",
      "9      E  \n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw.head(10))\n",
    "print(X_test_raw.head(10))\n",
    "print('*' * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc4059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all\n",
      "                        Name Platform  Year_of_Release         Genre  \\\n",
      "0                 Wii Sports      Wii           2006.0        Sports   \n",
      "1          Super Mario Bros.      NES           1985.0      Platform   \n",
      "2             Mario Kart Wii      Wii           2008.0        Racing   \n",
      "3          Wii Sports Resort      Wii           2009.0        Sports   \n",
      "4   Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing   \n",
      "5                     Tetris       GB           1989.0        Puzzle   \n",
      "6      New Super Mario Bros.       DS           2006.0      Platform   \n",
      "7                   Wii Play      Wii           2006.0          Misc   \n",
      "8  New Super Mario Bros. Wii      Wii           2009.0      Platform   \n",
      "9                  Duck Hunt      NES           1984.0       Shooter   \n",
      "\n",
      "  Publisher  NA_Sales  EU_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
      "0  Nintendo     41.36     28.96         8.45         82.53          76.0   \n",
      "1  Nintendo     29.08      3.58         0.77         40.24           NaN   \n",
      "2  Nintendo     15.68     12.76         3.29         35.52          82.0   \n",
      "3  Nintendo     15.61     10.93         2.95         32.77          80.0   \n",
      "4  Nintendo     11.27      8.89         1.00         31.37           NaN   \n",
      "5  Nintendo     23.20      2.26         0.58         30.26           NaN   \n",
      "6  Nintendo     11.28      9.14         2.88         29.80          89.0   \n",
      "7  Nintendo     13.96      9.18         2.84         28.92          58.0   \n",
      "8  Nintendo     14.44      6.94         2.24         28.32          87.0   \n",
      "9  Nintendo     26.93      0.63         0.47         28.31           NaN   \n",
      "\n",
      "   Critic_Count User_Score  User_Count Developer Rating  \n",
      "0          51.0          8       322.0  Nintendo      E  \n",
      "1           NaN        NaN         NaN       NaN    NaN  \n",
      "2          73.0        8.3       709.0  Nintendo      E  \n",
      "3          73.0          8       192.0  Nintendo      E  \n",
      "4           NaN        NaN         NaN       NaN    NaN  \n",
      "5           NaN        NaN         NaN       NaN    NaN  \n",
      "6          65.0        8.5       431.0  Nintendo      E  \n",
      "7          41.0        6.6       129.0  Nintendo      E  \n",
      "8          80.0        8.4       594.0  Nintendo      E  \n",
      "9           NaN        NaN         NaN       NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"X_all\")\n",
    "print(X_all.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3dda77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24147/2277753913.py:52: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_roman\"] = s.str.contains(ROMAN_RE, regex=True).astype(int)\n",
      "/tmp/ipykernel_24147/2277753913.py:53: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_edition_word\"] = s.str.contains(EDITION_RE, regex=True).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "EDITION_RE = re.compile(\n",
    "    r\"\\b(remaster(ed)?|hd|definitive|ultimate|complete|collector'?s|\"\n",
    "    r\"game of the year|goty|gold|deluxe|premium|special|limited|edition|\"\n",
    "    r\"director'?s cut|anniversary|bundle|collection)\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "ROMAN_RE = re.compile(r\"\\b(i{1,3}|iv|v|vi{0,3}|ix|x|xi|xii|xiii|xiv|xv)\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "def normalize_name(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\").fillna(\"__MISSING__\").str.lower()\n",
    "    # unify separators\n",
    "    s = s.str.replace(r\"[™®©]\", \"\", regex=True)\n",
    "    s = s.str.replace(r\"[\\(\\)\\[\\]\\{\\}]\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"[/:;,\\.\\!\\?\\|\\\\]\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"[-_]+\", \" \", regex=True)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "def split_base(s: pd.Series) -> pd.Series:\n",
    "    # base before ':' or long dash patterns (common subtitle separators)\n",
    "    s2 = s.str.replace(r\"\\s*:\\s*\", \" : \", regex=True)\n",
    "    # split on \":\" or \" - \" (keep left)\n",
    "    base = s2.str.split(r\"\\s:\\s|\\s-\\s|\\s—\\s\", n=1, expand=True)[0]\n",
    "    base = base.str.strip()\n",
    "    return base.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "def franchise_key(s: pd.Series) -> pd.Series:\n",
    "    s = s.copy()\n",
    "    s = s.str.replace(EDITION_RE, \" \", regex=True)\n",
    "    s = s.str.replace(ROMAN_RE, \" \", regex=True)\n",
    "    s = s.str.replace(r\"\\b\\d+\\b\", \" \", regex=True)          # sequel numbers / years in title\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "# usage (на X_all)\n",
    "if \"Name\" in X_all.columns:\n",
    "    X_all[\"Name_norm\"] = normalize_name(X_all[\"Name\"])\n",
    "    X_all[\"Name_base\"] = split_base(X_all[\"Name_norm\"])\n",
    "    X_all[\"Franchise_key\"] = franchise_key(X_all[\"Name_base\"])\n",
    "\n",
    "\n",
    "def add_name_flags(df):\n",
    "    s = df[\"Name_norm\"].astype(\"string\")\n",
    "    df[\"name_len\"] = s.str.len().fillna(0).astype(int)\n",
    "    df[\"name_words\"] = s.str.split().str.len().fillna(0).astype(int)\n",
    "    df[\"has_colon_or_dash\"] = s.str.contains(r\"\\s:\\s|\\s-\\s|\\s—\\s\", regex=True).astype(int)\n",
    "    df[\"has_digit\"] = s.str.contains(r\"\\d\").astype(int)\n",
    "    df[\"has_roman\"] = s.str.contains(ROMAN_RE, regex=True).astype(int)\n",
    "    df[\"has_edition_word\"] = s.str.contains(EDITION_RE, regex=True).astype(int)\n",
    "    return df\n",
    "\n",
    "if \"Name_norm\" in X_all.columns:\n",
    "    X_all = add_name_flags(X_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d026958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def add_oof_mean_count_features(\n",
    "    X: pd.DataFrame,\n",
    "    y,\n",
    "    X_test: pd.DataFrame,\n",
    "    keys,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "    alpha=5.0,          # smoothing strength; 0 = без сглаживания\n",
    "    fill_value=\"__MISSING__\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Добавляет OOF признаки:\n",
    "      - <key>__jp_mean  : OOF mean (optionally smoothed)\n",
    "      - <key>__jp_cnt   : OOF count\n",
    "    и для test — статистики по full train.\n",
    "    \"\"\"\n",
    "    if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "        y = np.asarray(y).reshape(-1)\n",
    "    else:\n",
    "        y = np.asarray(y).reshape(-1)\n",
    "\n",
    "    assert len(X) == len(y), \"X and y must have same length\"\n",
    "\n",
    "    X = X.reset_index(drop=True).copy()\n",
    "    X_test = X_test.reset_index(drop=True).copy()\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    global_mean = float(np.mean(y))\n",
    "\n",
    "    def _compute_for_key(key_col: str):\n",
    "        # гарантируем отсутствие NA в ключе\n",
    "        X[key_col] = X[key_col].astype(\"string\").fillna(fill_value)\n",
    "        X_test[key_col] = X_test[key_col].astype(\"string\").fillna(fill_value)\n",
    "\n",
    "        oof_mean = np.full(len(X), global_mean, dtype=float)\n",
    "        oof_cnt  = np.zeros(len(X), dtype=float)\n",
    "\n",
    "        for tr_idx, va_idx in kf.split(X):\n",
    "            tr_keys = X.loc[tr_idx, key_col].values\n",
    "\n",
    "            stats = (\n",
    "                pd.DataFrame({key_col: tr_keys, \"y\": y[tr_idx]})\n",
    "                .groupby(key_col)[\"y\"]\n",
    "                .agg([\"mean\", \"count\"])\n",
    "            )\n",
    "\n",
    "            va_keys = X.loc[va_idx, key_col]\n",
    "            m = va_keys.map(stats[\"mean\"])\n",
    "            c = va_keys.map(stats[\"count\"])\n",
    "\n",
    "            m = m.fillna(global_mean).astype(float).values\n",
    "            c = c.fillna(0).astype(float).values\n",
    "\n",
    "            if alpha and alpha > 0:\n",
    "                # smoothed mean: (m*c + global*alpha)/(c+alpha)\n",
    "                m = (m * c + global_mean * alpha) / (c + alpha)\n",
    "\n",
    "            oof_mean[va_idx] = m\n",
    "            oof_cnt[va_idx]  = c\n",
    "\n",
    "        # full-train stats for test\n",
    "        full_stats = (\n",
    "            pd.DataFrame({key_col: X[key_col].values, \"y\": y})\n",
    "            .groupby(key_col)[\"y\"]\n",
    "            .agg([\"mean\", \"count\"])\n",
    "        )\n",
    "\n",
    "        te_m = X_test[key_col].map(full_stats[\"mean\"]).fillna(global_mean).astype(float).values\n",
    "        te_c = X_test[key_col].map(full_stats[\"count\"]).fillna(0).astype(float).values\n",
    "        if alpha and alpha > 0:\n",
    "            te_m = (te_m * te_c + global_mean * alpha) / (te_c + alpha)\n",
    "\n",
    "        X[f\"{key_col}__jp_mean\"] = oof_mean\n",
    "        X[f\"{key_col}__jp_cnt\"]  = oof_cnt\n",
    "        X_test[f\"{key_col}__jp_mean\"] = te_m\n",
    "        X_test[f\"{key_col}__jp_cnt\"]  = te_c\n",
    "\n",
    "    for k in keys:\n",
    "        if k in X.columns and k in X_test.columns:\n",
    "            _compute_for_key(k)\n",
    "        else:\n",
    "            print(f\"SKIP '{k}': not present in both X and X_test\")\n",
    "\n",
    "    return X, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3f0f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_cols: ['Name']\n",
      "cat_cols: ['Platform', 'Genre', 'Publisher', 'User_Score', 'Developer', 'Rating', 'Name_norm', 'Name_base', 'Franchise_key']\n",
      "num_cols: ['Year_of_Release', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Global_Sales', 'Critic_Score', 'Critic_Count', 'User_Count', 'name_len', 'name_words', 'has_colon_or_dash', 'has_digit', 'has_roman', 'has_edition_word']\n",
      "NUM: 14 cols -> (21735, 14)\n",
      "CAT: 9 cols -> OHE shape (21735, 200)\n",
      "TEXT 'Name': TF-IDF shape (21735, 76512), vocab=76512\n",
      "TOTAL features: 76726\n",
      "X_train_proc: (16719, 76726) X_test_proc: (5016, 76726)\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS ON ALL DATA (train+test), THEN SPLIT BACK\n",
    "# =========================\n",
    "\n",
    "def make_ohe(min_freq: int):\n",
    "    \"\"\"Совместимость со sklearn: sparse_output (новый) vs sparse (старый).\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", min_frequency=min_freq, sparse_output=True)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", min_frequency=min_freq, sparse=True)\n",
    "\n",
    "def preprocess_all_data(\n",
    "    X_all_df: pd.DataFrame,\n",
    "    text_cols,\n",
    "    cat_cols,\n",
    "    num_cols,\n",
    "    min_freq: int = 50,\n",
    "    tfidf_max_features: int = 80000,\n",
    "):\n",
    "    mats = []\n",
    "\n",
    "    # 1) NUM\n",
    "    if len(num_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy=\"median\")\n",
    "        num_scaler = StandardScaler(with_mean=False)\n",
    "        num_data = num_scaler.fit_transform(num_imputer.fit_transform(X_all_df[num_cols]))\n",
    "        mats.append(sparse.csr_matrix(num_data))\n",
    "        print(f\"NUM: {len(num_cols)} cols -> {num_data.shape}\")\n",
    "\n",
    "    # 2) CAT (ИСПРАВЛЕНО!)\n",
    "    if len(cat_cols) > 0:\n",
    "        cat_df = X_all_df[cat_cols].fillna(\"__MISSING__\").astype(str)\n",
    "        ohe = make_ohe(min_freq)\n",
    "        cat_ohe = ohe.fit_transform(cat_df)\n",
    "        mats.append(cat_ohe.tocsr())\n",
    "        print(f\"CAT: {len(cat_cols)} cols -> OHE shape {cat_ohe.shape}\")\n",
    "\n",
    "    # 3) TEXT (TF-IDF)\n",
    "    def _flatten_1d(x):\n",
    "        arr = np.asarray(x).ravel().astype(str)\n",
    "        return np.where((arr == 'nan') | (arr == 'None') | (arr == '<NA>'), '', arr)\n",
    "\n",
    "    for c in text_cols:\n",
    "        # ИСПРАВЛЕНИЕ: fillna ПЕРЕД astype\n",
    "        text_data = X_all_df[c].fillna(\"\").astype(str).values\n",
    "        text_data = _flatten_1d(text_data.reshape(-1, 1))\n",
    "        \n",
    "        tfidf = TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=(3, 5),\n",
    "            min_df=2,\n",
    "            max_features=tfidf_max_features,\n",
    "        )\n",
    "        tfidf_mat = tfidf.fit_transform(text_data)\n",
    "        mats.append(tfidf_mat.tocsr())\n",
    "        print(f\"TEXT '{c}': TF-IDF shape {tfidf_mat.shape}, vocab={len(tfidf.vocabulary_)}\")\n",
    "\n",
    "    # stack\n",
    "    X_proc = sparse.hstack(mats, format=\"csr\")\n",
    "    print(f\"TOTAL features: {X_proc.shape[1]}\")\n",
    "    return X_proc\n",
    "\n",
    "# Выбираем колонки\n",
    "text_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_all.columns]\n",
    "\n",
    "cat_cols_all = X_all.select_dtypes(include=[\"object\", \"category\", \"bool\", \"string\"]).columns.tolist()\n",
    "cat_cols = [c for c in cat_cols_all if c not in set(text_cols)]\n",
    "\n",
    "num_cols = [c for c in X_all.columns if c not in set(cat_cols) and c not in set(text_cols)]\n",
    "\n",
    "print(\"text_cols:\", text_cols)\n",
    "print(\"cat_cols:\", cat_cols)\n",
    "print(\"num_cols:\", num_cols)\n",
    "\n",
    "X_all_proc = preprocess_all_data(\n",
    "    X_all,\n",
    "    text_cols=text_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    num_cols=num_cols,\n",
    "    min_freq=50,\n",
    "    tfidf_max_features=80000,\n",
    ")\n",
    "\n",
    "n_train = len(X_train_raw)\n",
    "X_train_proc = X_all_proc[:n_train]\n",
    "X_test_proc  = X_all_proc[n_train:]\n",
    "\n",
    "print(\"X_train_proc:\", X_train_proc.shape, \"X_test_proc:\", X_test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b090866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge][fold 1] MAE=0.002759 RMSE=0.005082\n",
      "[Ridge][fold 2] MAE=0.002634 RMSE=0.004881\n",
      "[Ridge][fold 3] MAE=0.002831 RMSE=0.005253\n",
      "[Ridge][fold 4] MAE=0.002787 RMSE=0.005156\n",
      "[Ridge][fold 5] MAE=0.002700 RMSE=0.004971\n",
      "Ridge: MAE mean=0.002742 std=0.000069 | RMSE mean=0.005069 std=0.000132\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CV: RIDGE (on processed)\n",
    "# =========================\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def cv_oof_ridge(X_proc, y_series: pd.Series, cv, alpha: float = 2.0):\n",
    "    oof = np.zeros(len(y_series), dtype=float)\n",
    "    fold_scores = []\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_proc, y_series), 1):\n",
    "        m = Ridge(alpha=alpha)\n",
    "        m.fit(X_proc[tr_idx], y_series.iloc[tr_idx])\n",
    "        pred = np.clip(m.predict(X_proc[va_idx]), 0, None)\n",
    "        oof[va_idx] = pred\n",
    "        mae = float(mean_absolute_error(y_series.iloc[va_idx], pred))\n",
    "        r = rmse(y_series.iloc[va_idx], pred)\n",
    "        fold_scores.append((mae, r))\n",
    "        print(f\"[Ridge][fold {fold}] MAE={mae:.6f} RMSE={r:.6f}\")\n",
    "    maes = np.array([s[0] for s in fold_scores])\n",
    "    rmses = np.array([s[1] for s in fold_scores])\n",
    "    print(f\"Ridge: MAE mean={maes.mean():.6f} std={maes.std():.6f} | RMSE mean={rmses.mean():.6f} std={rmses.std():.6f}\")\n",
    "    return oof, fold_scores\n",
    "\n",
    "oof_ridge, ridge_scores = cv_oof_ridge(X_train_proc, y, cv, alpha=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a29223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0755420\ttest: 0.0826102\tbest: 0.0826102 (0)\ttotal: 58.7ms\tremaining: 5m 52s\n",
      "200:\tlearn: 0.0290304\ttest: 0.0323422\tbest: 0.0323422 (200)\ttotal: 2.34s\tremaining: 1m 7s\n",
      "400:\tlearn: 0.0208751\ttest: 0.0262431\tbest: 0.0262431 (400)\ttotal: 4.76s\tremaining: 1m 6s\n",
      "600:\tlearn: 0.0167465\ttest: 0.0236797\tbest: 0.0236797 (600)\ttotal: 7.03s\tremaining: 1m 3s\n",
      "800:\tlearn: 0.0137924\ttest: 0.0223172\tbest: 0.0223172 (800)\ttotal: 11.8s\tremaining: 1m 16s\n",
      "1000:\tlearn: 0.0121560\ttest: 0.0217573\tbest: 0.0217573 (1000)\ttotal: 17.8s\tremaining: 1m 28s\n",
      "1200:\tlearn: 0.0109160\ttest: 0.0213974\tbest: 0.0213974 (1200)\ttotal: 22.9s\tremaining: 1m 31s\n",
      "1400:\tlearn: 0.0099390\ttest: 0.0211208\tbest: 0.0211208 (1400)\ttotal: 27.4s\tremaining: 1m 29s\n",
      "1600:\tlearn: 0.0091809\ttest: 0.0209107\tbest: 0.0209107 (1600)\ttotal: 30.3s\tremaining: 1m 23s\n",
      "1800:\tlearn: 0.0085450\ttest: 0.0207766\tbest: 0.0207695 (1748)\ttotal: 33s\tremaining: 1m 17s\n",
      "2000:\tlearn: 0.0079716\ttest: 0.0206086\tbest: 0.0206085 (1998)\ttotal: 35.6s\tremaining: 1m 11s\n",
      "2200:\tlearn: 0.0074489\ttest: 0.0204539\tbest: 0.0204534 (2199)\ttotal: 38.6s\tremaining: 1m 6s\n",
      "2400:\tlearn: 0.0070236\ttest: 0.0203315\tbest: 0.0203315 (2400)\ttotal: 41.5s\tremaining: 1m 2s\n",
      "2600:\tlearn: 0.0067434\ttest: 0.0202462\tbest: 0.0202441 (2598)\ttotal: 44.6s\tremaining: 58.3s\n",
      "2800:\tlearn: 0.0064505\ttest: 0.0201972\tbest: 0.0201970 (2799)\ttotal: 47.9s\tremaining: 54.7s\n",
      "3000:\tlearn: 0.0061892\ttest: 0.0201512\tbest: 0.0201407 (2980)\ttotal: 50.8s\tremaining: 50.7s\n",
      "3200:\tlearn: 0.0059660\ttest: 0.0201009\tbest: 0.0201009 (3199)\ttotal: 53.8s\tremaining: 47s\n",
      "3400:\tlearn: 0.0057782\ttest: 0.0200496\tbest: 0.0200486 (3392)\ttotal: 58.7s\tremaining: 44.9s\n",
      "3600:\tlearn: 0.0056024\ttest: 0.0200058\tbest: 0.0200054 (3597)\ttotal: 1m 3s\tremaining: 42.5s\n",
      "3800:\tlearn: 0.0054176\ttest: 0.0199285\tbest: 0.0199283 (3798)\ttotal: 1m 7s\tremaining: 39s\n",
      "4000:\tlearn: 0.0052603\ttest: 0.0198628\tbest: 0.0198623 (3995)\ttotal: 1m 10s\tremaining: 35.2s\n",
      "4200:\tlearn: 0.0051399\ttest: 0.0198396\tbest: 0.0198394 (4198)\ttotal: 1m 13s\tremaining: 31.6s\n",
      "4400:\tlearn: 0.0050011\ttest: 0.0198168\tbest: 0.0198156 (4399)\ttotal: 1m 17s\tremaining: 28.1s\n",
      "4600:\tlearn: 0.0048711\ttest: 0.0197817\tbest: 0.0197781 (4568)\ttotal: 1m 20s\tremaining: 24.4s\n",
      "4800:\tlearn: 0.0047374\ttest: 0.0197549\tbest: 0.0197549 (4800)\ttotal: 1m 23s\tremaining: 20.7s\n",
      "5000:\tlearn: 0.0046240\ttest: 0.0197286\tbest: 0.0197283 (4999)\ttotal: 1m 25s\tremaining: 17.2s\n",
      "5200:\tlearn: 0.0045389\ttest: 0.0197140\tbest: 0.0197111 (5150)\ttotal: 1m 28s\tremaining: 13.6s\n",
      "5400:\tlearn: 0.0044408\ttest: 0.0197103\tbest: 0.0197100 (5397)\ttotal: 1m 32s\tremaining: 10.3s\n",
      "5600:\tlearn: 0.0043547\ttest: 0.0196979\tbest: 0.0196955 (5550)\ttotal: 1m 37s\tremaining: 6.94s\n",
      "5800:\tlearn: 0.0042867\ttest: 0.0196856\tbest: 0.0196856 (5800)\ttotal: 1m 41s\tremaining: 3.49s\n",
      "5999:\tlearn: 0.0042278\ttest: 0.0196704\tbest: 0.0196700 (5995)\ttotal: 1m 44s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01967000133\n",
      "bestIteration = 5995\n",
      "\n",
      "Shrink model to first 5996 iterations.\n",
      "[CatBoost][fold 1] MAE=0.019425 RMSE=0.090336 best_iter=5995\n",
      "0:\tlearn: 0.0773813\ttest: 0.0757330\tbest: 0.0757330 (0)\ttotal: 12ms\tremaining: 1m 11s\n",
      "200:\tlearn: 0.0306821\ttest: 0.0305112\tbest: 0.0305112 (200)\ttotal: 2.5s\tremaining: 1m 12s\n",
      "400:\tlearn: 0.0216927\ttest: 0.0247814\tbest: 0.0247814 (400)\ttotal: 5.04s\tremaining: 1m 10s\n",
      "600:\tlearn: 0.0171123\ttest: 0.0224709\tbest: 0.0224368 (594)\ttotal: 7.45s\tremaining: 1m 6s\n",
      "800:\tlearn: 0.0143357\ttest: 0.0213764\tbest: 0.0213764 (800)\ttotal: 10s\tremaining: 1m 5s\n",
      "1000:\tlearn: 0.0124068\ttest: 0.0209518\tbest: 0.0209508 (995)\ttotal: 12.6s\tremaining: 1m 3s\n",
      "1200:\tlearn: 0.0109048\ttest: 0.0205308\tbest: 0.0205308 (1200)\ttotal: 15.1s\tremaining: 1m\n",
      "1400:\tlearn: 0.0099028\ttest: 0.0202724\tbest: 0.0202724 (1400)\ttotal: 18s\tremaining: 58.9s\n",
      "1600:\tlearn: 0.0090756\ttest: 0.0200793\tbest: 0.0200793 (1600)\ttotal: 21.4s\tremaining: 58.8s\n",
      "1800:\tlearn: 0.0084090\ttest: 0.0200008\tbest: 0.0200007 (1790)\ttotal: 25.8s\tremaining: 1m\n",
      "2000:\tlearn: 0.0078512\ttest: 0.0198376\tbest: 0.0198376 (2000)\ttotal: 29.8s\tremaining: 59.5s\n",
      "2200:\tlearn: 0.0074529\ttest: 0.0197291\tbest: 0.0197285 (2196)\ttotal: 33.1s\tremaining: 57.1s\n",
      "2400:\tlearn: 0.0070266\ttest: 0.0196463\tbest: 0.0196451 (2396)\ttotal: 36.3s\tremaining: 54.4s\n",
      "2600:\tlearn: 0.0066632\ttest: 0.0195793\tbest: 0.0195793 (2600)\ttotal: 39.4s\tremaining: 51.5s\n",
      "2800:\tlearn: 0.0063497\ttest: 0.0195309\tbest: 0.0195274 (2789)\ttotal: 42.6s\tremaining: 48.6s\n",
      "3000:\tlearn: 0.0060507\ttest: 0.0194641\tbest: 0.0194602 (2987)\ttotal: 45.8s\tremaining: 45.8s\n",
      "3200:\tlearn: 0.0057807\ttest: 0.0193874\tbest: 0.0193859 (3192)\ttotal: 49.1s\tremaining: 43s\n",
      "3400:\tlearn: 0.0056030\ttest: 0.0193652\tbest: 0.0193554 (3371)\ttotal: 53.6s\tremaining: 41s\n",
      "3600:\tlearn: 0.0054504\ttest: 0.0193123\tbest: 0.0193123 (3600)\ttotal: 59.5s\tremaining: 39.7s\n",
      "3800:\tlearn: 0.0053054\ttest: 0.0192835\tbest: 0.0192833 (3797)\ttotal: 1m 3s\tremaining: 36.6s\n",
      "4000:\tlearn: 0.0051799\ttest: 0.0192596\tbest: 0.0192592 (3997)\ttotal: 1m 6s\tremaining: 33.2s\n",
      "4200:\tlearn: 0.0050357\ttest: 0.0192308\tbest: 0.0192295 (4185)\ttotal: 1m 9s\tremaining: 29.8s\n",
      "4400:\tlearn: 0.0049200\ttest: 0.0192137\tbest: 0.0192137 (4399)\ttotal: 1m 13s\tremaining: 26.5s\n",
      "4600:\tlearn: 0.0047949\ttest: 0.0192020\tbest: 0.0192017 (4590)\ttotal: 1m 16s\tremaining: 23.2s\n",
      "4800:\tlearn: 0.0046952\ttest: 0.0191922\tbest: 0.0191867 (4762)\ttotal: 1m 19s\tremaining: 19.9s\n",
      "5000:\tlearn: 0.0046121\ttest: 0.0191882\tbest: 0.0191818 (4922)\ttotal: 1m 23s\tremaining: 16.6s\n",
      "5200:\tlearn: 0.0045160\ttest: 0.0191767\tbest: 0.0191719 (5133)\ttotal: 1m 26s\tremaining: 13.3s\n",
      "5400:\tlearn: 0.0044293\ttest: 0.0191560\tbest: 0.0191560 (5399)\ttotal: 1m 32s\tremaining: 10.3s\n",
      "5600:\tlearn: 0.0043354\ttest: 0.0191373\tbest: 0.0191311 (5577)\ttotal: 1m 36s\tremaining: 6.91s\n",
      "5800:\tlearn: 0.0042688\ttest: 0.0191182\tbest: 0.0191182 (5800)\ttotal: 1m 40s\tremaining: 3.43s\n",
      "5999:\tlearn: 0.0041906\ttest: 0.0191074\tbest: 0.0191072 (5998)\ttotal: 1m 43s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01910719541\n",
      "bestIteration = 5998\n",
      "\n",
      "Shrink model to first 5999 iterations.\n",
      "[CatBoost][fold 2] MAE=0.018846 RMSE=0.111036 best_iter=5998\n",
      "0:\tlearn: 0.0775255\ttest: 0.0738783\tbest: 0.0738783 (0)\ttotal: 12.4ms\tremaining: 1m 14s\n",
      "200:\tlearn: 0.0303211\ttest: 0.0317011\tbest: 0.0317011 (200)\ttotal: 2.73s\tremaining: 1m 18s\n",
      "400:\tlearn: 0.0216953\ttest: 0.0267866\tbest: 0.0267866 (400)\ttotal: 5.37s\tremaining: 1m 14s\n",
      "600:\tlearn: 0.0172832\ttest: 0.0244554\tbest: 0.0244554 (600)\ttotal: 8.44s\tremaining: 1m 15s\n",
      "800:\tlearn: 0.0147738\ttest: 0.0230575\tbest: 0.0230575 (800)\ttotal: 11s\tremaining: 1m 11s\n",
      "1000:\tlearn: 0.0129140\ttest: 0.0224582\tbest: 0.0224552 (999)\ttotal: 14.9s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.0114496\ttest: 0.0217805\tbest: 0.0217805 (1200)\ttotal: 19.1s\tremaining: 1m 16s\n",
      "1400:\tlearn: 0.0104590\ttest: 0.0214067\tbest: 0.0214067 (1400)\ttotal: 23.4s\tremaining: 1m 16s\n",
      "1600:\tlearn: 0.0096415\ttest: 0.0210872\tbest: 0.0210872 (1599)\ttotal: 26s\tremaining: 1m 11s\n",
      "1800:\tlearn: 0.0088994\ttest: 0.0208503\tbest: 0.0208418 (1795)\ttotal: 28.5s\tremaining: 1m 6s\n",
      "2000:\tlearn: 0.0083060\ttest: 0.0206233\tbest: 0.0206233 (2000)\ttotal: 31.1s\tremaining: 1m 2s\n",
      "2200:\tlearn: 0.0077397\ttest: 0.0204182\tbest: 0.0204182 (2200)\ttotal: 33.6s\tremaining: 58s\n",
      "2400:\tlearn: 0.0072898\ttest: 0.0202842\tbest: 0.0202830 (2396)\ttotal: 36.2s\tremaining: 54.2s\n",
      "2600:\tlearn: 0.0069562\ttest: 0.0201898\tbest: 0.0201881 (2585)\ttotal: 38.8s\tremaining: 50.7s\n",
      "2800:\tlearn: 0.0066614\ttest: 0.0201076\tbest: 0.0201076 (2800)\ttotal: 41.6s\tremaining: 47.5s\n",
      "3000:\tlearn: 0.0063631\ttest: 0.0199992\tbest: 0.0199992 (3000)\ttotal: 44.3s\tremaining: 44.3s\n",
      "3200:\tlearn: 0.0060951\ttest: 0.0199110\tbest: 0.0199106 (3195)\ttotal: 48.6s\tremaining: 42.5s\n",
      "3400:\tlearn: 0.0058896\ttest: 0.0198613\tbest: 0.0198503 (3390)\ttotal: 53.1s\tremaining: 40.6s\n",
      "3600:\tlearn: 0.0057015\ttest: 0.0198139\tbest: 0.0198136 (3598)\ttotal: 56.1s\tremaining: 37.4s\n",
      "3800:\tlearn: 0.0055395\ttest: 0.0197473\tbest: 0.0197470 (3798)\ttotal: 58.7s\tremaining: 34s\n",
      "4000:\tlearn: 0.0053759\ttest: 0.0197021\tbest: 0.0196998 (3984)\ttotal: 1m 1s\tremaining: 30.8s\n",
      "4200:\tlearn: 0.0052180\ttest: 0.0196645\tbest: 0.0196638 (4192)\ttotal: 1m 4s\tremaining: 27.6s\n",
      "4400:\tlearn: 0.0050557\ttest: 0.0195889\tbest: 0.0195889 (4400)\ttotal: 1m 7s\tremaining: 24.4s\n",
      "4600:\tlearn: 0.0049427\ttest: 0.0195462\tbest: 0.0195459 (4596)\ttotal: 1m 10s\tremaining: 21.4s\n",
      "4800:\tlearn: 0.0048393\ttest: 0.0195041\tbest: 0.0195029 (4791)\ttotal: 1m 13s\tremaining: 18.3s\n",
      "5000:\tlearn: 0.0047229\ttest: 0.0194752\tbest: 0.0194752 (4999)\ttotal: 1m 15s\tremaining: 15.2s\n",
      "5200:\tlearn: 0.0046086\ttest: 0.0194434\tbest: 0.0194434 (5200)\ttotal: 1m 18s\tremaining: 12.1s\n",
      "5400:\tlearn: 0.0045176\ttest: 0.0194236\tbest: 0.0194236 (5400)\ttotal: 1m 23s\tremaining: 9.26s\n",
      "5600:\tlearn: 0.0044309\ttest: 0.0194072\tbest: 0.0194070 (5598)\ttotal: 1m 28s\tremaining: 6.29s\n",
      "5800:\tlearn: 0.0043423\ttest: 0.0193822\tbest: 0.0193817 (5764)\ttotal: 1m 31s\tremaining: 3.15s\n",
      "5999:\tlearn: 0.0042714\ttest: 0.0193683\tbest: 0.0193668 (5984)\ttotal: 1m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01936684856\n",
      "bestIteration = 5984\n",
      "\n",
      "Shrink model to first 5985 iterations.\n",
      "[CatBoost][fold 3] MAE=0.019107 RMSE=0.137668 best_iter=5984\n",
      "0:\tlearn: 0.0759064\ttest: 0.0816353\tbest: 0.0816353 (0)\ttotal: 12.8ms\tremaining: 1m 16s\n",
      "200:\tlearn: 0.0284991\ttest: 0.0341086\tbest: 0.0341086 (200)\ttotal: 2.62s\tremaining: 1m 15s\n",
      "400:\tlearn: 0.0212195\ttest: 0.0277376\tbest: 0.0277376 (400)\ttotal: 5.1s\tremaining: 1m 11s\n",
      "600:\tlearn: 0.0169445\ttest: 0.0252574\tbest: 0.0252574 (600)\ttotal: 7.76s\tremaining: 1m 9s\n",
      "800:\tlearn: 0.0143427\ttest: 0.0238302\tbest: 0.0238302 (800)\ttotal: 10.4s\tremaining: 1m 7s\n",
      "1000:\tlearn: 0.0126877\ttest: 0.0231149\tbest: 0.0231149 (1000)\ttotal: 13.1s\tremaining: 1m 5s\n",
      "1200:\tlearn: 0.0113692\ttest: 0.0226613\tbest: 0.0226485 (1196)\ttotal: 15.7s\tremaining: 1m 2s\n",
      "1400:\tlearn: 0.0101089\ttest: 0.0222726\tbest: 0.0222725 (1399)\ttotal: 18.3s\tremaining: 1m\n",
      "1600:\tlearn: 0.0090875\ttest: 0.0219081\tbest: 0.0219075 (1599)\ttotal: 21.1s\tremaining: 58s\n",
      "1800:\tlearn: 0.0084214\ttest: 0.0217033\tbest: 0.0217033 (1800)\ttotal: 26s\tremaining: 1m\n",
      "2000:\tlearn: 0.0077083\ttest: 0.0214341\tbest: 0.0214299 (1991)\ttotal: 30.6s\tremaining: 1m 1s\n",
      "2200:\tlearn: 0.0072421\ttest: 0.0213286\tbest: 0.0213286 (2200)\ttotal: 33.5s\tremaining: 57.9s\n",
      "2400:\tlearn: 0.0068141\ttest: 0.0211879\tbest: 0.0211879 (2400)\ttotal: 36.6s\tremaining: 54.8s\n",
      "2600:\tlearn: 0.0065022\ttest: 0.0211051\tbest: 0.0210995 (2597)\ttotal: 39.7s\tremaining: 51.9s\n",
      "2800:\tlearn: 0.0062220\ttest: 0.0210490\tbest: 0.0210478 (2790)\ttotal: 42.8s\tremaining: 48.8s\n",
      "3000:\tlearn: 0.0059367\ttest: 0.0209878\tbest: 0.0209878 (3000)\ttotal: 45.8s\tremaining: 45.7s\n",
      "3200:\tlearn: 0.0057017\ttest: 0.0209336\tbest: 0.0209331 (3199)\ttotal: 48.7s\tremaining: 42.6s\n",
      "3400:\tlearn: 0.0054904\ttest: 0.0208656\tbest: 0.0208645 (3399)\ttotal: 51.7s\tremaining: 39.5s\n",
      "3600:\tlearn: 0.0053008\ttest: 0.0208443\tbest: 0.0208412 (3596)\ttotal: 54.5s\tremaining: 36.3s\n",
      "3800:\tlearn: 0.0051379\ttest: 0.0208142\tbest: 0.0208136 (3790)\ttotal: 57.5s\tremaining: 33.3s\n",
      "4000:\tlearn: 0.0049945\ttest: 0.0208042\tbest: 0.0207855 (3960)\ttotal: 1m 2s\tremaining: 31s\n",
      "4200:\tlearn: 0.0048592\ttest: 0.0207786\tbest: 0.0207784 (4191)\ttotal: 1m 7s\tremaining: 28.7s\n",
      "4400:\tlearn: 0.0047498\ttest: 0.0207635\tbest: 0.0207560 (4309)\ttotal: 1m 10s\tremaining: 25.8s\n",
      "4600:\tlearn: 0.0046235\ttest: 0.0207439\tbest: 0.0207373 (4568)\ttotal: 1m 13s\tremaining: 22.4s\n",
      "4800:\tlearn: 0.0045072\ttest: 0.0207118\tbest: 0.0207103 (4770)\ttotal: 1m 16s\tremaining: 19s\n",
      "5000:\tlearn: 0.0044214\ttest: 0.0207174\tbest: 0.0207077 (4858)\ttotal: 1m 18s\tremaining: 15.7s\n",
      "5200:\tlearn: 0.0043318\ttest: 0.0207000\tbest: 0.0206999 (5199)\ttotal: 1m 21s\tremaining: 12.5s\n",
      "5400:\tlearn: 0.0042363\ttest: 0.0206913\tbest: 0.0206909 (5396)\ttotal: 1m 23s\tremaining: 9.31s\n",
      "5600:\tlearn: 0.0041704\ttest: 0.0206732\tbest: 0.0206715 (5578)\ttotal: 1m 26s\tremaining: 6.17s\n",
      "5800:\tlearn: 0.0041093\ttest: 0.0206601\tbest: 0.0206601 (5798)\ttotal: 1m 29s\tremaining: 3.06s\n",
      "5999:\tlearn: 0.0040435\ttest: 0.0206521\tbest: 0.0206495 (5983)\ttotal: 1m 31s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.02064954507\n",
      "bestIteration = 5983\n",
      "\n",
      "Shrink model to first 5984 iterations.\n",
      "[CatBoost][fold 4] MAE=0.020368 RMSE=0.107883 best_iter=5983\n",
      "0:\tlearn: 0.0782184\ttest: 0.0707651\tbest: 0.0707651 (0)\ttotal: 12.1ms\tremaining: 1m 12s\n",
      "200:\tlearn: 0.0295080\ttest: 0.0319056\tbest: 0.0319056 (200)\ttotal: 2.45s\tremaining: 1m 10s\n",
      "400:\tlearn: 0.0214399\ttest: 0.0265313\tbest: 0.0265313 (400)\ttotal: 6.14s\tremaining: 1m 25s\n",
      "600:\tlearn: 0.0168794\ttest: 0.0239445\tbest: 0.0239445 (600)\ttotal: 10.2s\tremaining: 1m 31s\n",
      "800:\tlearn: 0.0141924\ttest: 0.0227486\tbest: 0.0227486 (800)\ttotal: 14.3s\tremaining: 1m 32s\n",
      "1000:\tlearn: 0.0124182\ttest: 0.0221202\tbest: 0.0221202 (1000)\ttotal: 17s\tremaining: 1m 24s\n",
      "1200:\tlearn: 0.0110308\ttest: 0.0216174\tbest: 0.0216174 (1200)\ttotal: 19.5s\tremaining: 1m 18s\n",
      "1400:\tlearn: 0.0100613\ttest: 0.0213636\tbest: 0.0213636 (1400)\ttotal: 22.1s\tremaining: 1m 12s\n",
      "1600:\tlearn: 0.0091590\ttest: 0.0210519\tbest: 0.0210494 (1590)\ttotal: 24.7s\tremaining: 1m 7s\n",
      "1800:\tlearn: 0.0085143\ttest: 0.0209042\tbest: 0.0209012 (1795)\ttotal: 27.3s\tremaining: 1m 3s\n",
      "2000:\tlearn: 0.0079606\ttest: 0.0208368\tbest: 0.0208346 (1992)\ttotal: 29.9s\tremaining: 59.8s\n",
      "2200:\tlearn: 0.0074620\ttest: 0.0207077\tbest: 0.0206928 (2177)\ttotal: 32.5s\tremaining: 56.2s\n",
      "2400:\tlearn: 0.0070866\ttest: 0.0205982\tbest: 0.0205934 (2382)\ttotal: 35.3s\tremaining: 52.9s\n",
      "2600:\tlearn: 0.0067496\ttest: 0.0205443\tbest: 0.0205407 (2593)\ttotal: 38.1s\tremaining: 49.8s\n",
      "2800:\tlearn: 0.0064902\ttest: 0.0204745\tbest: 0.0204735 (2796)\ttotal: 40.8s\tremaining: 46.6s\n",
      "3000:\tlearn: 0.0062484\ttest: 0.0204356\tbest: 0.0204349 (2983)\ttotal: 43.6s\tremaining: 43.6s\n",
      "3200:\tlearn: 0.0059892\ttest: 0.0203754\tbest: 0.0203734 (3152)\ttotal: 48s\tremaining: 42s\n",
      "3400:\tlearn: 0.0057898\ttest: 0.0203520\tbest: 0.0203520 (3399)\ttotal: 52.7s\tremaining: 40.3s\n",
      "3600:\tlearn: 0.0056087\ttest: 0.0202895\tbest: 0.0202895 (3600)\ttotal: 56s\tremaining: 37.3s\n",
      "3800:\tlearn: 0.0054632\ttest: 0.0202775\tbest: 0.0202729 (3788)\ttotal: 58.9s\tremaining: 34.1s\n",
      "4000:\tlearn: 0.0053266\ttest: 0.0202357\tbest: 0.0202268 (3991)\ttotal: 1m 1s\tremaining: 30.8s\n",
      "4200:\tlearn: 0.0051664\ttest: 0.0202122\tbest: 0.0202065 (4176)\ttotal: 1m 4s\tremaining: 27.6s\n",
      "4400:\tlearn: 0.0050412\ttest: 0.0201848\tbest: 0.0201804 (4378)\ttotal: 1m 7s\tremaining: 24.4s\n",
      "4600:\tlearn: 0.0049229\ttest: 0.0201672\tbest: 0.0201651 (4569)\ttotal: 1m 10s\tremaining: 21.3s\n",
      "4800:\tlearn: 0.0048162\ttest: 0.0201458\tbest: 0.0201458 (4798)\ttotal: 1m 12s\tremaining: 18.2s\n",
      "5000:\tlearn: 0.0047179\ttest: 0.0201164\tbest: 0.0201162 (4997)\ttotal: 1m 15s\tremaining: 15.1s\n",
      "5200:\tlearn: 0.0046273\ttest: 0.0200962\tbest: 0.0200955 (5180)\ttotal: 1m 19s\tremaining: 12.2s\n",
      "5400:\tlearn: 0.0045452\ttest: 0.0200834\tbest: 0.0200770 (5339)\ttotal: 1m 24s\tremaining: 9.33s\n",
      "5600:\tlearn: 0.0044694\ttest: 0.0200553\tbest: 0.0200553 (5599)\ttotal: 1m 28s\tremaining: 6.32s\n",
      "5800:\tlearn: 0.0043787\ttest: 0.0200469\tbest: 0.0200456 (5775)\ttotal: 1m 31s\tremaining: 3.15s\n",
      "5999:\tlearn: 0.0043109\ttest: 0.0200292\tbest: 0.0200292 (5998)\ttotal: 1m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.02002915014\n",
      "bestIteration = 5998\n",
      "\n",
      "Shrink model to first 5999 iterations.\n",
      "[CatBoost][fold 5] MAE=0.019728 RMSE=0.113124 best_iter=5998\n",
      "CatBoost: MAE mean=0.019495 std=0.000528 | RMSE mean=0.112009 std=0.015148\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CV: CATBOOST (CPU only, without Name text cols)\n",
    "# =========================\n",
    "def make_catboost_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # CatBoost нормально принимает pandas.DataFrame. Для категорий лучше string + fillna.\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if str(out[c].dtype) in (\"object\", \"category\", \"string\", \"bool\"):\n",
    "            out[c] = out[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    return out\n",
    "\n",
    "def cv_oof_catboost(X_df: pd.DataFrame, y_series: pd.Series, cv):\n",
    "    # Удаляем текстовые Name фичи из CatBoost (их обрабатывает Ridge)\n",
    "    drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_df.columns]\n",
    "    X_cb = X_df.drop(columns=drop_cols).reset_index(drop=True)\n",
    "    X_cb = make_catboost_frame(X_cb)\n",
    "\n",
    "    cat_cols = X_cb.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "    cat_idx  = [X_cb.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    oof = np.zeros(len(y_series), dtype=float)\n",
    "    fold_scores = []\n",
    "    best_iters = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_cb, y_series), 1):\n",
    "        X_tr, X_va = X_cb.iloc[tr_idx], X_cb.iloc[va_idx]\n",
    "        y_tr, y_va = y_series.iloc[tr_idx], y_series.iloc[va_idx]\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"MAE\",\n",
    "            eval_metric=\"MAE\",\n",
    "            iterations=6000,\n",
    "            learning_rate=0.03,\n",
    "            depth=8,\n",
    "            l2_leaf_reg=6.0,\n",
    "            random_seed=RANDOM_STATE,\n",
    "            # CPU only (стабильнее, без требований к CUDA)\n",
    "            task_type=\"CPU\",\n",
    "            # регуляризация\n",
    "            subsample=0.8,\n",
    "            rsm=0.8,\n",
    "            bootstrap_type=\"Bernoulli\",\n",
    "            # контроль\n",
    "            verbose=200,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            cat_features=cat_idx,\n",
    "            eval_set=(X_va, y_va),\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=500,\n",
    "        )\n",
    "\n",
    "        pred = np.clip(model.predict(X_va), 0, None)\n",
    "        oof[va_idx] = pred\n",
    "\n",
    "        mae = float(mean_absolute_error(y_va, pred))\n",
    "        r = rmse(y_va, pred)\n",
    "        fold_scores.append((mae, r))\n",
    "        best_iters.append(int(model.get_best_iteration()))\n",
    "        print(f\"[CatBoost][fold {fold}] MAE={mae:.6f} RMSE={r:.6f} best_iter={best_iters[-1]}\")\n",
    "\n",
    "    maes = np.array([s[0] for s in fold_scores])\n",
    "    rmses = np.array([s[1] for s in fold_scores])\n",
    "    print(f\"CatBoost: MAE mean={maes.mean():.6f} std={maes.std():.6f} | RMSE mean={rmses.mean():.6f} std={rmses.std():.6f}\")\n",
    "\n",
    "    return oof, fold_scores, best_iters\n",
    "\n",
    "oof_cb, cb_scores, cb_best_iters = cv_oof_catboost(X_train_raw, y, cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee72f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ensemble: {'w': 0.0, 'mae': 0.0027422913654672246, 'rmse': 0.005070518376312814}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ENSEMBLE WEIGHT (grid search on OOF)\n",
    "# =========================\n",
    "weights = np.linspace(0, 1, 201)  # w = доля CatBoost\n",
    "best = {\"w\": None, \"mae\": np.inf, \"rmse\": np.inf}\n",
    "\n",
    "for w in weights:\n",
    "    ens = w * oof_cb + (1 - w) * oof_ridge\n",
    "    mae = float(mean_absolute_error(y, ens))\n",
    "    r = rmse(y, ens)\n",
    "    if mae < best[\"mae\"]:\n",
    "        best = {\"w\": float(w), \"mae\": mae, \"rmse\": r}\n",
    "\n",
    "print(\"Best ensemble:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6584e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def _prep_lookup_keys(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "\n",
    "    if \"Name_norm\" in df.columns:\n",
    "        out[\"Name_norm\"] = df[\"Name_norm\"].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    else:\n",
    "        s = df[\"Name\"].astype(\"string\").fillna(\"\")\n",
    "        s = s.str.lower()\n",
    "        s = s.str.replace(r\"[\\u2122\\u00ae]\", \"\", regex=True)     # ™ ®\n",
    "        s = s.str.replace(r\"[^0-9a-z]+\", \" \", regex=True)        # латиница+цифры\n",
    "        s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "        out[\"Name_norm\"] = s.replace(\"\", \"__MISSING__\")\n",
    "\n",
    "    out[\"Platform\"] = df[\"Platform\"].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "    year = pd.to_numeric(df[\"Year_of_Release\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    out[\"Year_of_Release\"] = year\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_lookup(train_df: pd.DataFrame, y: pd.Series, key_cols, min_cnt: int = 1) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Возвращает pd.Series с MultiIndex по key_cols и значениями median(y).\n",
    "    min_cnt позволяет отфильтровать редкие ключи (полезно на fallback уровнях).\n",
    "    \"\"\"\n",
    "    keys = _prep_lookup_keys(train_df)[key_cols]\n",
    "    tmp = keys.copy()\n",
    "    tmp[\"y\"] = y.values\n",
    "\n",
    "    g = tmp.groupby(key_cols)[\"y\"].agg([\"median\", \"count\"])\n",
    "    g = g[g[\"count\"] >= min_cnt]\n",
    "    return g[\"median\"]\n",
    "\n",
    "def apply_lookup(lookup: pd.Series, df: pd.DataFrame, key_cols):\n",
    "    keys = _prep_lookup_keys(df)[key_cols]\n",
    "    mi = pd.MultiIndex.from_frame(keys)\n",
    "    pred = lookup.reindex(mi).to_numpy()\n",
    "    found = ~pd.isna(pred)\n",
    "    return pred, found\n",
    "\n",
    "def oof_lookup_pred(df: pd.DataFrame, y: pd.Series, cv, key_cols, min_cnt: int = 1):\n",
    "    \"\"\"\n",
    "    OOF-lookup: на каждом фолде строим lookup только по train-fold,\n",
    "    применяем к val-fold.\n",
    "    \"\"\"\n",
    "    oof = np.full(len(df), np.nan, dtype=float)\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(df), 1):\n",
    "        lookup = build_lookup(df.iloc[tr_idx], y.iloc[tr_idx], key_cols, min_cnt=min_cnt)\n",
    "        pred_va, found_va = apply_lookup(lookup, df.iloc[va_idx], key_cols)\n",
    "        oof[va_idx] = pred_va  # NaN там, где не найдено\n",
    "\n",
    "        cov = float(np.mean(found_va))\n",
    "        # MAE только по найденным\n",
    "        if np.any(found_va):\n",
    "            mae = mean_absolute_error(y.iloc[va_idx].values[found_va], pred_va[found_va])\n",
    "        else:\n",
    "            mae = np.nan\n",
    "        print(f\"[OOF-LOOKUP][fold {fold}] coverage={cov:.2%}, MAE(found-only)={mae}\")\n",
    "\n",
    "    return oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ddb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0763669\ttest: 0.0840482\tbest: 0.0840482 (0)\ttotal: 20.9ms\tremaining: 10m 26s\n",
      "200:\tlearn: 0.0622395\ttest: 0.0695123\tbest: 0.0695123 (200)\ttotal: 2.78s\tremaining: 6m 52s\n",
      "400:\tlearn: 0.0579286\ttest: 0.0647283\tbest: 0.0647283 (400)\ttotal: 5.54s\tremaining: 6m 48s\n",
      "600:\tlearn: 0.0560376\ttest: 0.0623129\tbest: 0.0623129 (600)\ttotal: 8.29s\tremaining: 6m 45s\n",
      "800:\tlearn: 0.0546627\ttest: 0.0606705\tbest: 0.0606705 (800)\ttotal: 11.8s\tremaining: 7m 8s\n",
      "1000:\tlearn: 0.0536187\ttest: 0.0595491\tbest: 0.0595491 (1000)\ttotal: 16.2s\tremaining: 7m 48s\n",
      "1200:\tlearn: 0.0527798\ttest: 0.0588002\tbest: 0.0588002 (1200)\ttotal: 20.1s\tremaining: 8m 2s\n",
      "1400:\tlearn: 0.0521236\ttest: 0.0581229\tbest: 0.0581229 (1400)\ttotal: 22.9s\tremaining: 7m 46s\n",
      "1600:\tlearn: 0.0515760\ttest: 0.0576463\tbest: 0.0576463 (1600)\ttotal: 26s\tremaining: 7m 40s\n",
      "1800:\tlearn: 0.0510697\ttest: 0.0571808\tbest: 0.0571808 (1800)\ttotal: 29.1s\tremaining: 7m 35s\n",
      "2000:\tlearn: 0.0504660\ttest: 0.0566412\tbest: 0.0566409 (1999)\ttotal: 32.1s\tremaining: 7m 29s\n",
      "2200:\tlearn: 0.0497304\ttest: 0.0560356\tbest: 0.0560356 (2200)\ttotal: 35.3s\tremaining: 7m 25s\n",
      "2400:\tlearn: 0.0489065\ttest: 0.0553291\tbest: 0.0553291 (2400)\ttotal: 38.2s\tremaining: 7m 19s\n",
      "2600:\tlearn: 0.0481454\ttest: 0.0546574\tbest: 0.0546562 (2599)\ttotal: 41.2s\tremaining: 7m 13s\n",
      "2800:\tlearn: 0.0475812\ttest: 0.0541706\tbest: 0.0541706 (2800)\ttotal: 44.4s\tremaining: 7m 11s\n",
      "3000:\tlearn: 0.0471432\ttest: 0.0538133\tbest: 0.0538133 (3000)\ttotal: 49.6s\tremaining: 7m 26s\n",
      "3200:\tlearn: 0.0468014\ttest: 0.0535816\tbest: 0.0535816 (3200)\ttotal: 54.8s\tremaining: 7m 38s\n",
      "3400:\tlearn: 0.0465051\ttest: 0.0533772\tbest: 0.0533772 (3400)\ttotal: 59.1s\tremaining: 7m 42s\n",
      "3600:\tlearn: 0.0462405\ttest: 0.0531975\tbest: 0.0531975 (3600)\ttotal: 1m 2s\tremaining: 7m 35s\n",
      "3800:\tlearn: 0.0459999\ttest: 0.0530061\tbest: 0.0530061 (3800)\ttotal: 1m 5s\tremaining: 7m 28s\n",
      "4000:\tlearn: 0.0457835\ttest: 0.0528525\tbest: 0.0528523 (3994)\ttotal: 1m 8s\tremaining: 7m 21s\n",
      "4200:\tlearn: 0.0455745\ttest: 0.0527629\tbest: 0.0527629 (4200)\ttotal: 1m 10s\tremaining: 7m 14s\n",
      "4400:\tlearn: 0.0453702\ttest: 0.0526714\tbest: 0.0526705 (4377)\ttotal: 1m 13s\tremaining: 7m 6s\n",
      "4600:\tlearn: 0.0451864\ttest: 0.0525864\tbest: 0.0525860 (4598)\ttotal: 1m 15s\tremaining: 6m 58s\n",
      "4800:\tlearn: 0.0450319\ttest: 0.0525032\tbest: 0.0525032 (4800)\ttotal: 1m 18s\tremaining: 6m 51s\n",
      "5000:\tlearn: 0.0448790\ttest: 0.0524363\tbest: 0.0524360 (4999)\ttotal: 1m 21s\tremaining: 6m 47s\n",
      "5200:\tlearn: 0.0447181\ttest: 0.0523749\tbest: 0.0523749 (5200)\ttotal: 1m 25s\tremaining: 6m 48s\n",
      "5400:\tlearn: 0.0445837\ttest: 0.0523390\tbest: 0.0523390 (5400)\ttotal: 1m 29s\tremaining: 6m 48s\n",
      "5600:\tlearn: 0.0444822\ttest: 0.0522968\tbest: 0.0522961 (5594)\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "5800:\tlearn: 0.0443542\ttest: 0.0522568\tbest: 0.0522564 (5795)\ttotal: 1m 35s\tremaining: 6m 38s\n",
      "6000:\tlearn: 0.0442495\ttest: 0.0522110\tbest: 0.0522109 (5998)\ttotal: 1m 37s\tremaining: 6m 31s\n",
      "6200:\tlearn: 0.0441385\ttest: 0.0521784\tbest: 0.0521766 (6178)\ttotal: 1m 40s\tremaining: 6m 25s\n",
      "6400:\tlearn: 0.0440310\ttest: 0.0521419\tbest: 0.0521419 (6400)\ttotal: 1m 43s\tremaining: 6m 19s\n",
      "6600:\tlearn: 0.0439202\ttest: 0.0521112\tbest: 0.0521106 (6597)\ttotal: 1m 45s\tremaining: 6m 14s\n",
      "6800:\tlearn: 0.0438234\ttest: 0.0520792\tbest: 0.0520768 (6780)\ttotal: 1m 48s\tremaining: 6m 8s\n",
      "7000:\tlearn: 0.0437355\ttest: 0.0520611\tbest: 0.0520609 (6974)\ttotal: 1m 50s\tremaining: 6m 3s\n",
      "7200:\tlearn: 0.0436341\ttest: 0.0520060\tbest: 0.0520060 (7200)\ttotal: 1m 53s\tremaining: 5m 58s\n",
      "7400:\tlearn: 0.0435517\ttest: 0.0519849\tbest: 0.0519841 (7375)\ttotal: 1m 55s\tremaining: 5m 53s\n",
      "7600:\tlearn: 0.0434563\ttest: 0.0519497\tbest: 0.0519497 (7600)\ttotal: 1m 58s\tremaining: 5m 48s\n",
      "7800:\tlearn: 0.0433643\ttest: 0.0519041\tbest: 0.0519029 (7799)\ttotal: 2m\tremaining: 5m 43s\n",
      "8000:\tlearn: 0.0432913\ttest: 0.0518733\tbest: 0.0518730 (7999)\ttotal: 2m 4s\tremaining: 5m 42s\n",
      "8200:\tlearn: 0.0432223\ttest: 0.0518595\tbest: 0.0518595 (8199)\ttotal: 2m 9s\tremaining: 5m 44s\n",
      "8400:\tlearn: 0.0431549\ttest: 0.0518470\tbest: 0.0518464 (8398)\ttotal: 2m 14s\tremaining: 5m 46s\n",
      "8600:\tlearn: 0.0430763\ttest: 0.0518325\tbest: 0.0518325 (8600)\ttotal: 2m 17s\tremaining: 5m 43s\n",
      "8800:\tlearn: 0.0430069\ttest: 0.0518133\tbest: 0.0518131 (8798)\ttotal: 2m 20s\tremaining: 5m 39s\n",
      "9000:\tlearn: 0.0429375\ttest: 0.0517947\tbest: 0.0517944 (8995)\ttotal: 2m 24s\tremaining: 5m 36s\n",
      "9200:\tlearn: 0.0428693\ttest: 0.0517661\tbest: 0.0517657 (9198)\ttotal: 2m 26s\tremaining: 5m 32s\n",
      "9400:\tlearn: 0.0427954\ttest: 0.0517365\tbest: 0.0517365 (9400)\ttotal: 2m 30s\tremaining: 5m 28s\n",
      "9600:\tlearn: 0.0427170\ttest: 0.0517124\tbest: 0.0517118 (9596)\ttotal: 2m 33s\tremaining: 5m 25s\n",
      "9800:\tlearn: 0.0426451\ttest: 0.0516894\tbest: 0.0516883 (9794)\ttotal: 2m 36s\tremaining: 5m 22s\n",
      "10000:\tlearn: 0.0425804\ttest: 0.0516648\tbest: 0.0516648 (10000)\ttotal: 2m 39s\tremaining: 5m 18s\n",
      "10200:\tlearn: 0.0425035\ttest: 0.0516299\tbest: 0.0516299 (10200)\ttotal: 2m 42s\tremaining: 5m 15s\n",
      "10400:\tlearn: 0.0424404\ttest: 0.0516091\tbest: 0.0516087 (10398)\ttotal: 2m 47s\tremaining: 5m 15s\n",
      "10600:\tlearn: 0.0423777\ttest: 0.0515805\tbest: 0.0515805 (10600)\ttotal: 2m 52s\tremaining: 5m 15s\n",
      "10800:\tlearn: 0.0423199\ttest: 0.0515632\tbest: 0.0515622 (10795)\ttotal: 2m 55s\tremaining: 5m 12s\n",
      "11000:\tlearn: 0.0422554\ttest: 0.0515426\tbest: 0.0515424 (10994)\ttotal: 2m 58s\tremaining: 5m 8s\n",
      "11200:\tlearn: 0.0421907\ttest: 0.0515018\tbest: 0.0515016 (11199)\ttotal: 3m 1s\tremaining: 5m 4s\n",
      "11400:\tlearn: 0.0421364\ttest: 0.0514839\tbest: 0.0514822 (11377)\ttotal: 3m 4s\tremaining: 5m\n",
      "11600:\tlearn: 0.0420799\ttest: 0.0514653\tbest: 0.0514650 (11596)\ttotal: 3m 7s\tremaining: 4m 56s\n",
      "11800:\tlearn: 0.0420133\ttest: 0.0514397\tbest: 0.0514364 (11795)\ttotal: 3m 10s\tremaining: 4m 53s\n",
      "12000:\tlearn: 0.0419673\ttest: 0.0514236\tbest: 0.0514235 (11999)\ttotal: 3m 13s\tremaining: 4m 49s\n",
      "12200:\tlearn: 0.0419100\ttest: 0.0514019\tbest: 0.0514019 (12200)\ttotal: 3m 15s\tremaining: 4m 45s\n",
      "12400:\tlearn: 0.0418572\ttest: 0.0513743\tbest: 0.0513741 (12394)\ttotal: 3m 18s\tremaining: 4m 42s\n",
      "12600:\tlearn: 0.0417998\ttest: 0.0513408\tbest: 0.0513406 (12598)\ttotal: 3m 23s\tremaining: 4m 41s\n",
      "12800:\tlearn: 0.0417448\ttest: 0.0513154\tbest: 0.0513154 (12800)\ttotal: 3m 29s\tremaining: 4m 41s\n",
      "13000:\tlearn: 0.0416953\ttest: 0.0512950\tbest: 0.0512949 (12999)\ttotal: 3m 33s\tremaining: 4m 39s\n",
      "13200:\tlearn: 0.0416454\ttest: 0.0512809\tbest: 0.0512807 (13197)\ttotal: 3m 36s\tremaining: 4m 35s\n",
      "13400:\tlearn: 0.0415984\ttest: 0.0512697\tbest: 0.0512697 (13400)\ttotal: 3m 39s\tremaining: 4m 32s\n",
      "13600:\tlearn: 0.0415372\ttest: 0.0512481\tbest: 0.0512481 (13600)\ttotal: 3m 42s\tremaining: 4m 28s\n",
      "13800:\tlearn: 0.0414810\ttest: 0.0512210\tbest: 0.0512210 (13800)\ttotal: 3m 46s\tremaining: 4m 25s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     33\u001b[39m X_tr, X_va, y_tr, y_va = train_test_split(\n\u001b[32m     34\u001b[39m     X_cb_full, y, test_size=\u001b[32m0.15\u001b[39m, random_state=RANDOM_STATE\n\u001b[32m     35\u001b[39m )\n\u001b[32m     39\u001b[39m cb_final = CatBoostRegressor(\n\u001b[32m     40\u001b[39m     loss_function=\u001b[33m\"\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m     eval_metric=\u001b[33m\"\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     verbose=\u001b[32m200\u001b[39m,\n\u001b[32m     67\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mcb_final\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m pred_cb = np.clip(cb_final.predict(X_cb_test), \u001b[32m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     80\u001b[39m w = best[\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m best[\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.5\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/catboost/core.py:5873\u001b[39m, in \u001b[36mCatBoostRegressor.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5872\u001b[39m     CatBoostRegressor._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5874\u001b[39m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5875\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5876\u001b[39m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/catboost/core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/catboost/core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# FINAL FIT + PREDICT TEST\n",
    "# =========================\n",
    "# Ridge final on all processed train\n",
    "ridge_final = Ridge(alpha=2.0)\n",
    "ridge_final.fit(X_train_proc, y)\n",
    "pred_ridge = np.clip(ridge_final.predict(X_test_proc), 0, None)\n",
    "\n",
    "# CatBoost final: fit with holdout for early stopping\n",
    "drop_cols = [c for c in [\"Name\", \"Name_root\"] if c in X_train_raw.columns]\n",
    "X_cb_full = X_train_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "X_cb_test = X_test_raw.drop(columns=drop_cols).reset_index(drop=True)\n",
    "# FIX\n",
    "for df in (X_cb_full, X_cb_test):\n",
    "    if \"Global_Sales\" in df.columns:\n",
    "        df.drop(columns=[\"Global_Sales\"], inplace=True)\n",
    "\n",
    "X_cb_full = make_catboost_frame(X_cb_full)\n",
    "X_cb_test = make_catboost_frame(X_cb_test)\n",
    "\n",
    "cat_cols = X_cb_full.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "\n",
    "for c in cat_cols:\n",
    "    X_cb_full[c] = X_cb_full[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    X_cb_test[c] = X_cb_test[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "# 3) после приведения считаем индексы\n",
    "cat_idx = [X_cb_full.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "cat_cols = X_cb_full.select_dtypes(include=[\"object\",\"category\",\"string\",\"bool\"]).columns.tolist()\n",
    "cat_idx  = [X_cb_full.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_cb_full, y, test_size=0.15, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "cb_final = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    eval_metric=\"MAE\",\n",
    "    iterations=20000,\n",
    "\n",
    "    # best_params (Optuna best)\n",
    "    bootstrap_type=\"Bernoulli\",\n",
    "    grow_policy=\"Depthwise\",\n",
    "    learning_rate=0.005336574757662616,\n",
    "    depth=11,\n",
    "    l2_leaf_reg=47.22898537933602,\n",
    "    rsm=0.9069506230060724,\n",
    "    min_data_in_leaf=183,\n",
    "    random_strength=10.226847977218757,\n",
    "    one_hot_max_size=26,\n",
    "    max_ctr_complexity=7,\n",
    "    border_count=177,\n",
    "    leaf_estimation_method=\"Exact\",\n",
    "    leaf_estimation_iterations=7,\n",
    "    subsample=0.687791476319972,\n",
    "    model_size_reg=0.93981939840869,\n",
    "    feature_border_type=\"GreedyLogSum\",\n",
    "    score_function=\"L2\",\n",
    "\n",
    "    # fixed / infra\n",
    "    random_seed=RANDOM_STATE,\n",
    "    task_type=\"CPU\",\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "\n",
    "cb_final.fit(\n",
    "    X_tr, y_tr,\n",
    "    cat_features=cat_idx,\n",
    "    eval_set=(X_va, y_va),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=500,\n",
    ")\n",
    "\n",
    "pred_cb = np.clip(cb_final.predict(X_cb_test), 0, None)\n",
    "\n",
    "w = best[\"w\"] if best[\"w\"] is not None else 0.5\n",
    "pred_ens = np.clip(w * pred_cb + (1 - w) * pred_ridge, 0, None)\n",
    "\n",
    "print(f\"Pred stats: ridge_mean={pred_ridge.mean():.4f}, cb_mean={pred_cb.mean():.4f}, ens_mean={pred_ens.mean():.4f}, w={w}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# LOOKUP (train -> test)\n",
    "# =========================\n",
    "# Уровень 1: строгий ключ (Name_norm + Platform + Year)\n",
    "key1 = [\"Name_norm\", \"Platform\", \"Year_of_Release\"]\n",
    "lk1 = build_lookup(X_train_raw, y, key1, min_cnt=1)\n",
    "lk1_pred, lk1_found = apply_lookup(lk1, X_test_raw, key1)\n",
    "\n",
    "pred_final = pred_ens.copy()\n",
    "pred_final[lk1_found] = lk1_pred[lk1_found]\n",
    "\n",
    "print(f\"Lookup L1 hit-rate: {lk1_found.mean():.2%} ({lk1_found.sum()}/{len(lk1_found)})\")\n",
    "\n",
    "# (опционально) Уровень 2: fallback без года (иногда даёт сильный буст, но аккуратно)\n",
    "# Если включаете — лучше поставить min_cnt>=2, чтобы уменьшить шум.\n",
    "key2 = [\"Name_norm\", \"Platform\"]\n",
    "lk2 = build_lookup(X_train_raw, y, key2, min_cnt=2)\n",
    "lk2_pred, lk2_found = apply_lookup(lk2, X_test_raw, key2)\n",
    "\n",
    "# применяем fallback ТОЛЬКО там, где L1 не нашёлся\n",
    "need2 = (~lk1_found) & (lk2_found)\n",
    "pred_final[need2] = lk2_pred[need2]\n",
    "\n",
    "print(f\"Lookup L2 extra hit-rate: {need2.mean():.2%} (+{need2.sum()} rows)\")\n",
    "\n",
    "pred_final = np.clip(pred_final, 0, None)\n",
    "\n",
    "print(f\"Final stats: ens_mean={pred_ens.mean():.4f}, final_mean={pred_final.mean():.4f}\")\n",
    "\n",
    "# Оценка качества на тренировочных данных\n",
    "y_pred_train = cb_final.predict(X_tr)\n",
    "print('Mean Absolute Error = ', mean_absolute_error(y_tr, y_pred_train))\n",
    "print('Mean Absolute Percentage Error = ', mean_absolute_percentage_error(y_tr, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f8cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>JP_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  JP_Sales\n",
       "0   1      0.07\n",
       "1   2      0.00\n",
       "2   3      0.00\n",
       "3   4      0.00\n",
       "4   5      0.00\n",
       "5   6      0.01\n",
       "6   7      0.01\n",
       "7   8      0.12\n",
       "8   9      3.37\n",
       "9  10      0.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# SUBMISSION\n",
    "# =========================\n",
    "sub = pd.DataFrame({\"Id\": test_ids, \"JP_Sales\": pred_ens})\n",
    "sub[\"JP_Sales\"] = sub[\"JP_Sales\"].round(2)\n",
    "sub.to_csv(\"sub_external.csv\", index=False)\n",
    "sub.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
