{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc1be59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (11703, 13)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # :contentReference[oaicite:6]{index=6}\n",
    "\n",
    "def rmse_metric(y_true, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred)) \n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_PATH = \"Video_Games.csv\"\n",
    "TEST_PATH  = \"Video_Games_Test.csv\"\n",
    "TARGET = \"JP_Sales\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "y = train_df[TARGET].astype(float)\n",
    "X = train_df.drop(columns=[TARGET], errors=\"ignore\").copy()\n",
    "\n",
    "# как в lab_fixed: 'Name' почти уникален — его обычно разумно убрать\n",
    "if \"Name\" in X.columns:\n",
    "    X = X.drop(columns=[\"Name\"])\n",
    "\n",
    "# User_Score иногда строка ('tbd') → в число\n",
    "if \"User_Score\" in X.columns:\n",
    "    X[\"User_Score\"] = pd.to_numeric(X[\"User_Score\"], errors=\"coerce\")\n",
    "\n",
    "# ВАЖНО: НЕ удаляем Platform/Genre/Publisher/Developer/Rating — они останутся как категориальные (dtype object)\n",
    "print(\"X shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5de8fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def make_cat_features_indices(X_df: pd.DataFrame):\n",
    "    cat_cols = [c for c in X_df.columns if X_df[c].dtype == \"object\"]\n",
    "    cat_idx = [X_df.columns.get_loc(c) for c in cat_cols]\n",
    "    return cat_cols, cat_idx\n",
    "\n",
    "def cv_oof_catboost(X_df: pd.DataFrame, y: pd.Series, cv: KFold):\n",
    "    cat_cols, cat_idx = make_cat_features_indices(X_df)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "    best_iters = []\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_df, y), 1):\n",
    "        X_tr = X_df.iloc[tr_idx].copy()\n",
    "        X_va = X_df.iloc[va_idx].copy()\n",
    "        y_tr = y.iloc[tr_idx]\n",
    "        y_va = y.iloc[va_idx]\n",
    "\n",
    "        # cat missing → строка (устойчивее)\n",
    "        for c in cat_cols:\n",
    "            X_tr[c] = X_tr[c].fillna(\"__MISSING__\")\n",
    "            X_va[c] = X_va[c].fillna(\"__MISSING__\")\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"MAE\",\n",
    "            iterations=20000,\n",
    "            learning_rate=0.025,\n",
    "            depth=9,\n",
    "            l2_leaf_reg=6,\n",
    "            random_strength=1.0,\n",
    "            bootstrap_type=\"Bayesian\",\n",
    "            bagging_temperature=1.0,\n",
    "            random_seed=RANDOM_STATE,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            cat_features=cat_idx,\n",
    "            eval_set=(X_va, y_va),\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=500\n",
    "        )\n",
    "\n",
    "        pred = model.predict(X_va)\n",
    "        pred = np.clip(pred, 0, None)\n",
    "\n",
    "        oof[va_idx] = pred\n",
    "        mae = mean_absolute_error(y_va, pred)\n",
    "        rmse = rmse_metric(y_va, pred)\n",
    "        fold_scores.append((mae, rmse))\n",
    "        best_iters.append(model.get_best_iteration())\n",
    "\n",
    "        print(f\"[CatBoost][fold {fold}] MAE={mae:.6f} RMSE={rmse:.6f} best_iter={best_iters[-1]}\")\n",
    "\n",
    "    return oof, fold_scores, best_iters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67e8e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cv_oof_sklearn(estimator: Pipeline, X_df: pd.DataFrame, y: pd.Series, cv: KFold):\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_df, y), 1):\n",
    "        est = clone(estimator)\n",
    "        est.fit(X_df.iloc[tr_idx], y.iloc[tr_idx])\n",
    "        pred = est.predict(X_df.iloc[va_idx])\n",
    "        pred = np.clip(pred, 0, None)\n",
    "\n",
    "        oof[va_idx] = pred\n",
    "        mae = mean_absolute_error(y.iloc[va_idx], pred)\n",
    "        rmse = rmse_metric(y.iloc[va_idx], pred)  # вместо mean_squared_error(..., squared=False)\n",
    "        fold_scores.append((mae, rmse))\n",
    "\n",
    "        print(f\"[Ridge][fold {fold}] MAE={mae:.6f} RMSE={rmse:.6f}\")\n",
    "\n",
    "    return oof, fold_scores\n",
    "\n",
    "\n",
    "def summarize(scores, name):\n",
    "    maes = np.array([s[0] for s in scores], dtype=float)\n",
    "    rmses = np.array([s[1] for s in scores], dtype=float)\n",
    "    print(f\"{name}: MAE mean={maes.mean():.6f} std={maes.std():.6f} | RMSE mean={rmses.mean():.6f} std={rmses.std():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a44e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "def make_ridge_pipe(X_df, alpha=2.0, min_freq=50):\n",
    "    # категории: object/category/bool (при необходимости добавьте сюда int-коды, если они означают категории)\n",
    "    cat_cols = X_df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "    num_cols = [c for c in X_df.columns if c not in cat_cols]\n",
    "\n",
    "    num_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    # min_frequency есть не во всех версиях sklearn → fallback\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", min_frequency=min_freq)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    cat_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", ohe),\n",
    "    ])\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, num_cols),\n",
    "            (\"cat\", cat_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"model\", Ridge(alpha=alpha)),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32ed0261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ridge][fold 1] MAE=0.080631 RMSE=0.204857\n",
      "[Ridge][fold 2] MAE=0.086742 RMSE=0.258789\n",
      "[Ridge][fold 3] MAE=0.081969 RMSE=0.219856\n",
      "[Ridge][fold 4] MAE=0.086440 RMSE=0.288133\n",
      "[Ridge][fold 5] MAE=0.083084 RMSE=0.249227\n",
      "Ridge: MAE mean=0.083773 std=0.002430 | RMSE mean=0.244172 std=0.029355\n",
      "[CatBoost][fold 1] MAE=0.045963 RMSE=0.178358 best_iter=741\n",
      "[CatBoost][fold 2] MAE=0.055877 RMSE=0.228941 best_iter=1358\n",
      "[CatBoost][fold 3] MAE=0.049261 RMSE=0.192108 best_iter=1298\n",
      "[CatBoost][fold 4] MAE=0.055732 RMSE=0.250366 best_iter=692\n",
      "[CatBoost][fold 5] MAE=0.056192 RMSE=0.235533 best_iter=370\n",
      "CatBoost: MAE mean=0.052605 std=0.004211 | RMSE mean=0.217061 std=0.027248\n",
      "Best ensemble (by MAE): {'w': 1.0, 'mae': 0.05260450844678675, 'rmse': 0.21876032939569653}\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)  # :contentReference[oaicite:14]{index=14}\n",
    "\n",
    "ridge_pipe = make_ridge_pipe(X, alpha=2.0, min_freq=50)\n",
    "oof_ridge, ridge_scores = cv_oof_sklearn(ridge_pipe, X, y, cv)\n",
    "summarize(ridge_scores, \"Ridge\")\n",
    "\n",
    "\n",
    "oof_cb, cb_scores, cb_best_iters = cv_oof_catboost(X, y, cv)\n",
    "summarize(cb_scores, \"CatBoost\")\n",
    "\n",
    "# Подбор веса ансамбля по MAE на OOF\n",
    "weights = np.linspace(0, 1, 201)  # w = доля CatBoost\n",
    "best = {\"w\": None, \"mae\": np.inf, \"rmse\": np.inf}\n",
    "\n",
    "for w in weights:\n",
    "    ens = w * oof_cb + (1 - w) * oof_ridge\n",
    "    mae = mean_absolute_error(y, ens)\n",
    "    rmse = rmse_metric(y, ens)\n",
    "    if mae < best[\"mae\"]:\n",
    "        best = {\"w\": float(w), \"mae\": float(mae), \"rmse\": float(rmse)}\n",
    "\n",
    "print(\"Best ensemble (by MAE):\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cbf224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cols: ['Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating']\n",
      "Test cols : ['Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating']\n",
      "Extra in test: []\n",
      "Missing in test: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "test_X = test_df.drop(columns=[c for c in [TARGET] if c in test_df.columns], errors=\"ignore\").copy()\n",
    "\n",
    "# как в train: drop Name\n",
    "if \"Name\" in test_X.columns:\n",
    "    test_X = test_X.drop(columns=[\"Name\"])\n",
    "\n",
    "# User_Score -> numeric\n",
    "if \"User_Score\" in test_X.columns:\n",
    "    test_X[\"User_Score\"] = pd.to_numeric(test_X[\"User_Score\"], errors=\"coerce\")\n",
    "\n",
    "test_X = test_X.reindex(columns=X.columns)\n",
    "\n",
    "# 1) Ridge full\n",
    "ridge_pipe_final = make_ridge_pipe(X, alpha=2.0, min_freq=50)\n",
    "ridge_pipe_final.fit(X, y)\n",
    "pred_ridge = np.clip(ridge_pipe_final.predict(test_X), 0, None)\n",
    "\n",
    "# 2) CatBoost final с holdout\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.10, random_state=RANDOM_STATE)\n",
    "\n",
    "cat_cols = [c for c in [\"Platform\",\"Genre\",\"Publisher\",\"Developer\",\"Rating\"] if c in X_tr.columns]\n",
    "\n",
    "cat_cols = [c for c in [\"Platform\",\"Genre\",\"Publisher\",\"Developer\",\"Rating\"] if c in X_tr.columns]\n",
    "for c in cat_cols:\n",
    "    X_tr[c] = X_tr[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    X_va[c] = X_va[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    test_X[c] = test_X[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "cb_final = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    iterations=30000,\n",
    "    learning_rate=0.025,\n",
    "    depth=9,\n",
    "    l2_leaf_reg=6,\n",
    "    random_strength=1.0,\n",
    "    bootstrap_type=\"Bayesian\",\n",
    "    bagging_temperature=1.0,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "cb_final.fit(\n",
    "    X_tr, y_tr,\n",
    "    cat_features=cat_idx,\n",
    "    eval_set=(X_va, y_va),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=500\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train cols:\", list(X.columns))\n",
    "print(\"Test cols :\", list(test_X.columns))\n",
    "\n",
    "extra = sorted(set(test_X.columns) - set(X.columns))\n",
    "missing = sorted(set(X.columns) - set(test_X.columns))\n",
    "print(\"Extra in test:\", extra)\n",
    "print(\"Missing in test:\", missing)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bcc80b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>JP_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  JP_Sales\n",
       "0   1  0.069099\n",
       "1   2  0.000000\n",
       "2   3  0.000793\n",
       "3   4  0.001018\n",
       "4   5  0.000515"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cb = np.clip(cb_final.predict(test_X), 0, None)\n",
    "# 3) Ensemble\n",
    "w = best[\"w\"]  # вес CatBoost, найденный по OOF\n",
    "pred_ens = np.clip(w * pred_cb + (1 - w) * pred_ridge, 0, None)\n",
    "\n",
    "# 4) Submission\n",
    "if \"Id\" in test_df.columns:\n",
    "    sub = pd.DataFrame({\"Id\": test_df[\"Id\"], \"JP_Sales\": pred_ens})\n",
    "else:\n",
    "    sub = pd.DataFrame({\"Id\": np.arange(1, len(test_df) + 1), \"JP_Sales\": pred_ens})\n",
    "\n",
    "sub.to_csv(\"sub.csv\", index=False)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bfbde73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-03 18:15:42,229] A new study created in memory with name: no-name-6d4f445a-2f51-460f-b2b5-e7947c125b29\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "[I 2026-01-03 18:15:44,720] Trial 0 finished with value: 0.054956104769680894 and parameters: {'learning_rate': 0.14266627179116348, 'depth': 5, 'l2_leaf_reg': 8.625324090551356, 'random_strength': 2.8804100663021477, 'bagging_temperature': 3.7643452808916846, 'one_hot_max_size': 24, 'max_ctr_complexity': 1, 'border_count': 128}. Best is trial 0 with value: 0.054956104769680894.\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "[I 2026-01-03 18:16:21,043] Trial 1 finished with value: 0.04609947453320932 and parameters: {'learning_rate': 0.015614914989974115, 'depth': 8, 'l2_leaf_reg': 6.490076862793638, 'random_strength': 2.468820464144383, 'bagging_temperature': 3.8632655545308143, 'one_hot_max_size': 27, 'max_ctr_complexity': 4, 'border_count': 64}. Best is trial 1 with value: 0.04609947453320932.\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "[I 2026-01-03 18:16:44,561] Trial 2 finished with value: 0.05680272542415557 and parameters: {'learning_rate': 0.11171116701091907, 'depth': 10, 'l2_leaf_reg': 2.489588426661967, 'random_strength': 0.3756327805794568, 'bagging_temperature': 3.9877275875922082, 'one_hot_max_size': 19, 'max_ctr_complexity': 2, 'border_count': 254}. Best is trial 1 with value: 0.04609947453320932.\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "[W 2026-01-03 18:16:50,194] Trial 3 failed with parameters: {'learning_rate': 0.011376863533434063, 'depth': 9, 'l2_leaf_reg': 27.353251529960737, 'random_strength': 2.2653578898483233, 'bagging_temperature': 1.5097130232431524, 'one_hot_max_size': 9, 'max_ctr_complexity': 3, 'border_count': 64} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alehay/venvs/tf/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1933111/3003178533.py\", line 60, in objective\n",
      "    model.fit(\n",
      "  File \"/home/alehay/venvs/tf/lib/python3.12/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/alehay/venvs/tf/lib/python3.12/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/home/alehay/venvs/tf/lib/python3.12/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-03 18:16:50,195] Trial 3 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     72\u001b[39m TIME_BUDGET_MIN = \u001b[32m10\u001b[39m * \u001b[32m60\u001b[39m\n\u001b[32m     73\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTIME_BUDGET_MIN\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# секунды :contentReference[oaicite:5]{index=5}\u001b[39;49;00m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# один процесс на один GPU\u001b[39;49;00m\n\u001b[32m     79\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest MAE:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/optuna/study/_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/optuna/study/_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/optuna/study/_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/optuna/study/_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     26\u001b[39m params = {\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33meval_metric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mthread_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m,  \u001b[38;5;66;03m# задействуем CPU для хоста/препроцессинга\u001b[39;00m\n\u001b[32m     56\u001b[39m }\n\u001b[32m     59\u001b[39m model = CatBoostRegressor(**params)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks НЕ добавляем: на GPU запрещено :contentReference[oaicite:4]{index=4}\u001b[39;49;00m\n\u001b[32m     67\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m pred = np.clip(model.predict(X_va), \u001b[32m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mean_absolute_error(y_va, pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/catboost/core.py:5873\u001b[39m, in \u001b[36mCatBoostRegressor.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5872\u001b[39m     CatBoostRegressor._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5874\u001b[39m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5875\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5876\u001b[39m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/catboost/core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf/lib/python3.12/site-packages/catboost/core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ВАЖНО: X не должен содержать Id; test отдельно.\n",
    "# Категориальные признаки (у вас основные)\n",
    "cat_cols = [c for c in [\"Platform\",\"Genre\",\"Publisher\",\"Developer\",\"Rating\"] if c in X.columns]\n",
    "\n",
    "# Фиксируем holdout (быстро для тюнинга)\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Убедимся, что категории строки + заполнены пропуски\n",
    "for c in cat_cols:\n",
    "    X_tr[c] = X_tr[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    X_va[c] = X_va[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"loss_function\": \"MAE\",\n",
    "        \"eval_metric\": \"MAE\",\n",
    "\n",
    "        # GPU\n",
    "        \"task_type\": \"GPU\",\n",
    "        \"devices\": \"0\", \n",
    "\n",
    "        \"iterations\": 20000,\n",
    "\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True),\n",
    "\n",
    "        \"depth\": trial.suggest_int(\"depth\", 5, 10),\n",
    "\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 50.0, log=True),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.0, 6.0),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 4.0),\n",
    "\n",
    "        \"one_hot_max_size\": trial.suggest_int(\"one_hot_max_size\", 2, 30),\n",
    "\n",
    "        \"max_ctr_complexity\": trial.suggest_int(\"max_ctr_complexity\", 1, 5),\n",
    "\n",
    "        \"border_count\": trial.suggest_categorical(\"border_count\", [64, 128, 254]),\n",
    "\n",
    "        \"od_type\": \"Iter\",\n",
    "        \"od_wait\": 300,\n",
    "\n",
    "        \"random_seed\": RANDOM_STATE,\n",
    "        \"verbose\": False,\n",
    "        \"thread_count\": 10,  # задействуем CPU для хоста/препроцессингаы\n",
    "    }\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        cat_features=cat_cols,\n",
    "        eval_set=(X_va, y_va),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=300,\n",
    "        # callbacks НЕ добавляем: на GPU запрещено :contentReference[oaicite:4]{index=4}\n",
    "    )\n",
    "\n",
    "    pred = np.clip(model.predict(X_va), 0, None)\n",
    "    return mean_absolute_error(y_va, pred)\n",
    "\n",
    "TIME_BUDGET_MIN = 10 * 60\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(\n",
    "    objective,\n",
    "    timeout=TIME_BUDGET_MIN * 60,  # секунды :contentReference[oaicite:5]{index=5}\n",
    "    n_trials=10_000,         \n",
    "    n_jobs=1                       # один процесс на один GPU\n",
    ")\n",
    "\n",
    "print(\"Best MAE:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3a3cdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cols: ['Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating']\n",
      "Test cols : ['Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating']\n",
      "Extra in test: []\n",
      "Missing in test: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>JP_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.067769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  JP_Sales\n",
       "0   1  0.067769\n",
       "1   2  0.000004\n",
       "2   3  0.000226\n",
       "3   4  0.000000\n",
       "4   5  0.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "test_X = test_df.drop(columns=[c for c in [TARGET] if c in test_df.columns], errors=\"ignore\").copy()\n",
    "\n",
    "# как в train: drop Name\n",
    "if \"Name\" in test_X.columns:\n",
    "    test_X = test_X.drop(columns=[\"Name\"])\n",
    "\n",
    "# User_Score -> numeric\n",
    "if \"User_Score\" in test_X.columns:\n",
    "    test_X[\"User_Score\"] = pd.to_numeric(test_X[\"User_Score\"], errors=\"coerce\")\n",
    "\n",
    "test_X = test_X.reindex(columns=X.columns)\n",
    "\n",
    "# 1) Ridge full\n",
    "ridge_pipe_final = make_ridge_pipe(X, alpha=2.0, min_freq=50)\n",
    "ridge_pipe_final.fit(X, y)\n",
    "pred_ridge = np.clip(ridge_pipe_final.predict(test_X), 0, None)\n",
    "\n",
    "# 2) CatBoost final с holdout\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.10, random_state=RANDOM_STATE)\n",
    "\n",
    "cat_cols = [c for c in [\"Platform\",\"Genre\",\"Publisher\",\"Developer\",\"Rating\"] if c in X_tr.columns]\n",
    "\n",
    "cat_cols = [c for c in [\"Platform\",\"Genre\",\"Publisher\",\"Developer\",\"Rating\"] if c in X_tr.columns]\n",
    "for c in cat_cols:\n",
    "    X_tr[c] = X_tr[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    X_va[c] = X_va[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "    test_X[c] = test_X[c].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "cb_final = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    iterations=60000,\n",
    "    learning_rate= 0.010956168437531352,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=38.59897273605603,\n",
    "    random_strength=1.4518325715315628,\n",
    "    bootstrap_type=\"Bayesian\",\n",
    "    bagging_temperature=0.4562048980660218,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    verbose=False,\n",
    "    one_hot_max_size = 9,\n",
    "    max_ctr_complexity = 3,\n",
    "    border_count=64,\n",
    "\n",
    ")\n",
    "\n",
    "cb_final.fit(\n",
    "    X_tr, y_tr,\n",
    "    cat_features=cat_idx,\n",
    "    eval_set=(X_va, y_va),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=500\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train cols:\", list(X.columns))\n",
    "print(\"Test cols :\", list(test_X.columns))\n",
    "\n",
    "extra = sorted(set(test_X.columns) - set(X.columns))\n",
    "missing = sorted(set(X.columns) - set(test_X.columns))\n",
    "print(\"Extra in test:\", extra)\n",
    "print(\"Missing in test:\", missing)\n",
    "\n",
    "pred_cb = np.clip(cb_final.predict(test_X), 0, None)\n",
    "# 3) Ensemble\n",
    "w = best[\"w\"]  # вес CatBoost, найденный по OOF\n",
    "pred_ens = np.clip(w * pred_cb + (1 - w) * pred_ridge, 0, None)\n",
    "\n",
    "# 4) Submission\n",
    "if \"Id\" in test_df.columns:\n",
    "    sub = pd.DataFrame({\"Id\": test_df[\"Id\"], \"JP_Sales\": pred_ens})\n",
    "else:\n",
    "    sub = pd.DataFrame({\"Id\": np.arange(1, len(test_df) + 1), \"JP_Sales\": pred_ens})\n",
    "\n",
    "sub.to_csv(\"sub6.csv\", index=False)\n",
    "sub.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a1fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
